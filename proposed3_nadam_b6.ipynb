{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2743d5c",
   "metadata": {},
   "source": [
    "# 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b63b6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    }
   ],
   "source": [
    "from analysis_tools.common import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import sklearn\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "sklearn.random.seed(RANDOM_STATE)\n",
    "\n",
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083ee50",
   "metadata": {},
   "source": [
    "# 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6eba851",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  7.5s\n",
      "[########################################] | 100% Completed |  3.6s\n",
      "- Number of train full data: 4277\n",
      "- Number of test data: 2154\n"
     ]
    }
   ],
   "source": [
    "train_full_data_meta = pd.read_csv(join(PATH.input, 'train_df.csv'), index_col=0)\n",
    "test_data_meta       = pd.read_csv(join(PATH.input, 'test_df.csv'), index_col=0)\n",
    "\n",
    "with ProgressBar():\n",
    "    X_train_full = compute(*[delayed(cv2.imread)(path) for path in ls_file(PATH.train)])\n",
    "    X_test       = compute(*[delayed(cv2.imread)(path) for path in ls_file(PATH.test)])\n",
    "y_train_full = train_full_data_meta[['label']]\n",
    "    \n",
    "print(\"- Number of train full data:\", len(X_train_full))\n",
    "print(\"- Number of test data:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508182a",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e372118e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3.6s\n",
      "[########################################] | 100% Completed |  1.2s\n",
      "- Number of classes: 88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "IMG_SIZE    = 700\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "with ProgressBar():\n",
    "    X_train_full = np.array(compute(*[delayed(cv2.resize)(X, [IMG_SIZE, IMG_SIZE]) for X in X_train_full]))\n",
    "    X_test       = np.array(compute(*[delayed(cv2.resize)(X, [IMG_SIZE, IMG_SIZE]) for X in X_test]))\n",
    "y_enc = OneHotEncoder(sparse=False, dtype=bool)\n",
    "y_train_full = y_enc.fit_transform(y_train_full)\n",
    "n_classes = len(y_enc.categories_[0])\n",
    "print(\"- Number of classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1d1139",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aug_model = keras.models.Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "def preprocess(ds, training, batch_size, augment=True):\n",
    "    ds = ds.cache().batch(batch_size)\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=1000).prefetch(tf.data.AUTOTUNE)\n",
    "        if augment:\n",
    "            ds = ds.map(lambda X, y, sw: (aug_model(X), y, sw), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# fig, axes = plt.subplots(5, 15, figsize=(30, 10))\n",
    "# for row, ax_cols in enumerate(axes):\n",
    "#     for ax in ax_cols:\n",
    "#         ax.imshow(aug_model(X_train_full[row]))\n",
    "#         ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20862d",
   "metadata": {},
   "source": [
    "## 3.1 Fix pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aef44e53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train.shape: (3207, 700, 700, 3) (3207, 88)\n",
      "- val.shape: (1070, 700, 700, 3) (1070, 88)\n",
      "- test.shape: (2154, 700, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, stratify=y_train_full)\n",
    "sample_weight_train = compute_sample_weight(class_weight='balanced', y=y_train.argmax(1))\n",
    "sample_weight_val   = compute_sample_weight(class_weight='balanced', y=y_val.argmax(1))\n",
    "\n",
    "train_ds = preprocess(tf.data.Dataset.from_tensor_slices((X_train, y_train, sample_weight_train)), True, BATCH_SIZE)\n",
    "val_ds   = preprocess(tf.data.Dataset.from_tensor_slices((X_val, y_val, sample_weight_val)), False, BATCH_SIZE)\n",
    "test_ds  = preprocess(tf.data.Dataset.from_tensor_slices(X_test), False, BATCH_SIZE)\n",
    "\n",
    "print(\"- train.shape:\", X_train.shape, y_train.shape)\n",
    "print(\"- val.shape:\", X_val.shape, y_val.shape)\n",
    "print(\"- test.shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e1e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.metrics import F1Score\n",
    "\n",
    "def build_model(n_classes, strategy):\n",
    "    with strategy.scope():\n",
    "        base_model = keras.applications.EfficientNetB6(include_top=False, input_shape=input_shape)\n",
    "        base_model.trainable = False\n",
    "\n",
    "        inputs  = keras.Input(input_shape)\n",
    "        hidden  = base_model(inputs, training=False)\n",
    "        hidden  = keras.layers.GlobalAveragePooling2D()(hidden)\n",
    "        outputs = keras.layers.Dense(n_classes, activation='softmax')(hidden)\n",
    "        model   = keras.Model(inputs, outputs)\n",
    "        \n",
    "        model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=[F1Score(num_classes=n_classes, average='macro')])\n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5171581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/1000\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "101/101 [==============================] - 144s 801ms/step - loss: 3.0584 - f1_score: 0.1801 - val_loss: 2.0088 - val_f1_score: 0.2560\n",
      "Epoch 2/1000\n",
      "101/101 [==============================] - 71s 664ms/step - loss: 1.7621 - f1_score: 0.2843 - val_loss: 1.6602 - val_f1_score: 0.3408\n",
      "Epoch 3/1000\n",
      "101/101 [==============================] - 65s 577ms/step - loss: 1.4356 - f1_score: 0.3759 - val_loss: 1.4990 - val_f1_score: 0.3178\n",
      "Epoch 4/1000\n",
      "101/101 [==============================] - 66s 593ms/step - loss: 1.2536 - f1_score: 0.4239 - val_loss: 1.4076 - val_f1_score: 0.3725\n",
      "Epoch 5/1000\n",
      "101/101 [==============================] - 66s 592ms/step - loss: 1.1168 - f1_score: 0.4690 - val_loss: 1.3660 - val_f1_score: 0.3856\n",
      "Epoch 6/1000\n",
      "101/101 [==============================] - 71s 641ms/step - loss: 1.0268 - f1_score: 0.5020 - val_loss: 1.3296 - val_f1_score: 0.4257\n",
      "Epoch 7/1000\n",
      "101/101 [==============================] - 64s 569ms/step - loss: 0.9653 - f1_score: 0.5534 - val_loss: 1.2130 - val_f1_score: 0.4017\n",
      "Epoch 8/1000\n",
      "101/101 [==============================] - 66s 595ms/step - loss: 0.8983 - f1_score: 0.5662 - val_loss: 1.2361 - val_f1_score: 0.4611\n",
      "Epoch 9/1000\n",
      "101/101 [==============================] - 65s 579ms/step - loss: 0.8735 - f1_score: 0.5919 - val_loss: 1.1848 - val_f1_score: 0.4708\n",
      "Epoch 10/1000\n",
      "101/101 [==============================] - 65s 570ms/step - loss: 0.8265 - f1_score: 0.6013 - val_loss: 1.2020 - val_f1_score: 0.4621\n",
      "Epoch 11/1000\n",
      "101/101 [==============================] - 65s 580ms/step - loss: 0.7861 - f1_score: 0.6057 - val_loss: 1.1929 - val_f1_score: 0.4549\n",
      "Epoch 12/1000\n",
      "101/101 [==============================] - 64s 567ms/step - loss: 0.7380 - f1_score: 0.6320 - val_loss: 1.2030 - val_f1_score: 0.4408\n",
      "Epoch 13/1000\n",
      "101/101 [==============================] - 66s 595ms/step - loss: 0.6739 - f1_score: 0.6556 - val_loss: 1.1324 - val_f1_score: 0.5038\n",
      "Epoch 14/1000\n",
      "101/101 [==============================] - 65s 585ms/step - loss: 0.6828 - f1_score: 0.6676 - val_loss: 1.1963 - val_f1_score: 0.4839\n",
      "Epoch 15/1000\n",
      "101/101 [==============================] - 65s 574ms/step - loss: 0.6542 - f1_score: 0.6699 - val_loss: 1.1375 - val_f1_score: 0.5235\n",
      "Epoch 16/1000\n",
      "101/101 [==============================] - 66s 584ms/step - loss: 0.6447 - f1_score: 0.6813 - val_loss: 1.1322 - val_f1_score: 0.5001\n",
      "Epoch 17/1000\n",
      "101/101 [==============================] - 66s 590ms/step - loss: 0.6126 - f1_score: 0.6794 - val_loss: 1.1397 - val_f1_score: 0.4657\n",
      "Epoch 18/1000\n",
      "101/101 [==============================] - 66s 585ms/step - loss: 0.6222 - f1_score: 0.6758 - val_loss: 1.1172 - val_f1_score: 0.5032\n",
      "Epoch 19/1000\n",
      "101/101 [==============================] - 64s 573ms/step - loss: 0.5840 - f1_score: 0.6896 - val_loss: 1.1488 - val_f1_score: 0.4986\n",
      "Epoch 20/1000\n",
      "101/101 [==============================] - 64s 569ms/step - loss: 0.5542 - f1_score: 0.7097 - val_loss: 1.0901 - val_f1_score: 0.5145\n",
      "Epoch 21/1000\n",
      "101/101 [==============================] - 65s 585ms/step - loss: 0.5765 - f1_score: 0.7105 - val_loss: 1.0638 - val_f1_score: 0.5535\n",
      "Epoch 22/1000\n",
      "101/101 [==============================] - 64s 570ms/step - loss: 0.5359 - f1_score: 0.7077 - val_loss: 1.0584 - val_f1_score: 0.5781\n",
      "Epoch 23/1000\n",
      "101/101 [==============================] - 66s 582ms/step - loss: 0.4986 - f1_score: 0.7481 - val_loss: 1.0770 - val_f1_score: 0.5402\n",
      "Epoch 24/1000\n",
      "101/101 [==============================] - 65s 576ms/step - loss: 0.5134 - f1_score: 0.7160 - val_loss: 1.0469 - val_f1_score: 0.5324\n",
      "Epoch 25/1000\n",
      "101/101 [==============================] - 66s 585ms/step - loss: 0.5003 - f1_score: 0.7352 - val_loss: 1.1284 - val_f1_score: 0.5366\n",
      "Epoch 26/1000\n",
      "101/101 [==============================] - 66s 588ms/step - loss: 0.4983 - f1_score: 0.7317 - val_loss: 1.0470 - val_f1_score: 0.5411\n",
      "Epoch 27/1000\n",
      "101/101 [==============================] - 65s 582ms/step - loss: 0.4887 - f1_score: 0.7388 - val_loss: 1.0347 - val_f1_score: 0.5301\n",
      "Epoch 28/1000\n",
      "101/101 [==============================] - 65s 575ms/step - loss: 0.4588 - f1_score: 0.7587 - val_loss: 1.0690 - val_f1_score: 0.5397\n",
      "Epoch 29/1000\n",
      "101/101 [==============================] - 65s 580ms/step - loss: 0.4330 - f1_score: 0.7596 - val_loss: 1.0771 - val_f1_score: 0.5619\n",
      "Epoch 30/1000\n",
      "101/101 [==============================] - 63s 589ms/step - loss: 0.4600 - f1_score: 0.7515 - val_loss: 1.0877 - val_f1_score: 0.5439\n",
      "Epoch 31/1000\n",
      "101/101 [==============================] - 64s 574ms/step - loss: 0.4179 - f1_score: 0.7639 - val_loss: 1.0427 - val_f1_score: 0.5389\n",
      "Epoch 32/1000\n",
      "101/101 [==============================] - 65s 575ms/step - loss: 0.4438 - f1_score: 0.7654 - val_loss: 1.0770 - val_f1_score: 0.5474\n",
      "Epoch 33/1000\n",
      "101/101 [==============================] - 65s 579ms/step - loss: 0.4431 - f1_score: 0.7548 - val_loss: 0.9650 - val_f1_score: 0.5662\n",
      "Epoch 34/1000\n",
      "101/101 [==============================] - 64s 572ms/step - loss: 0.3980 - f1_score: 0.7688 - val_loss: 1.0182 - val_f1_score: 0.5554\n",
      "Epoch 35/1000\n",
      "101/101 [==============================] - 67s 592ms/step - loss: 0.4146 - f1_score: 0.7618 - val_loss: 1.0612 - val_f1_score: 0.5338\n",
      "Epoch 36/1000\n",
      "101/101 [==============================] - 64s 574ms/step - loss: 0.4028 - f1_score: 0.7745 - val_loss: 1.0771 - val_f1_score: 0.5423\n",
      "Epoch 37/1000\n",
      "101/101 [==============================] - 63s 561ms/step - loss: 0.3989 - f1_score: 0.7762 - val_loss: 1.0137 - val_f1_score: 0.5584\n",
      "Epoch 38/1000\n",
      "101/101 [==============================] - 73s 658ms/step - loss: 0.3919 - f1_score: 0.7780 - val_loss: 1.0318 - val_f1_score: 0.6081\n",
      "Epoch 39/1000\n",
      "101/101 [==============================] - 66s 587ms/step - loss: 0.3715 - f1_score: 0.7972 - val_loss: 1.0235 - val_f1_score: 0.5992\n",
      "Epoch 40/1000\n",
      "101/101 [==============================] - 64s 574ms/step - loss: 0.3764 - f1_score: 0.7720 - val_loss: 1.0129 - val_f1_score: 0.5880\n",
      "Epoch 41/1000\n",
      "101/101 [==============================] - 66s 586ms/step - loss: 0.3757 - f1_score: 0.7907 - val_loss: 1.0326 - val_f1_score: 0.5623\n",
      "Epoch 42/1000\n",
      "101/101 [==============================] - 66s 585ms/step - loss: 0.3745 - f1_score: 0.7865 - val_loss: 1.0621 - val_f1_score: 0.5922\n",
      "Epoch 43/1000\n",
      "101/101 [==============================] - 66s 585ms/step - loss: 0.3657 - f1_score: 0.7972 - val_loss: 1.0712 - val_f1_score: 0.5826\n",
      "Epoch 44/1000\n",
      "101/101 [==============================] - 66s 582ms/step - loss: 0.3546 - f1_score: 0.7935 - val_loss: 1.0584 - val_f1_score: 0.5880\n",
      "Epoch 45/1000\n",
      "101/101 [==============================] - 64s 569ms/step - loss: 0.3582 - f1_score: 0.7920 - val_loss: 1.0895 - val_f1_score: 0.5667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000\n",
      "101/101 [==============================] - 65s 578ms/step - loss: 0.3483 - f1_score: 0.8002 - val_loss: 1.0678 - val_f1_score: 0.5872\n",
      "Epoch 47/1000\n",
      "101/101 [==============================] - 64s 576ms/step - loss: 0.3469 - f1_score: 0.8077 - val_loss: 1.1100 - val_f1_score: 0.5651\n",
      "Epoch 48/1000\n",
      "101/101 [==============================] - 65s 578ms/step - loss: 0.3334 - f1_score: 0.7981 - val_loss: 1.1555 - val_f1_score: 0.5633\n",
      "Epoch 49/1000\n",
      "101/101 [==============================] - 64s 571ms/step - loss: 0.3307 - f1_score: 0.7944 - val_loss: 1.0713 - val_f1_score: 0.5700\n",
      "Epoch 50/1000\n",
      "101/101 [==============================] - 66s 593ms/step - loss: 0.3119 - f1_score: 0.8090 - val_loss: 1.1002 - val_f1_score: 0.5841\n",
      "Epoch 51/1000\n",
      "101/101 [==============================] - 65s 578ms/step - loss: 0.3181 - f1_score: 0.8073 - val_loss: 1.0997 - val_f1_score: 0.5799\n",
      "Epoch 52/1000\n",
      "101/101 [==============================] - 65s 580ms/step - loss: 0.3461 - f1_score: 0.8033 - val_loss: 1.0244 - val_f1_score: 0.5621\n",
      "Epoch 53/1000\n",
      "101/101 [==============================] - 65s 579ms/step - loss: 0.2942 - f1_score: 0.8220 - val_loss: 1.0075 - val_f1_score: 0.5699\n",
      "Epoch 54/1000\n",
      "101/101 [==============================] - 65s 585ms/step - loss: 0.3051 - f1_score: 0.8280 - val_loss: 1.0907 - val_f1_score: 0.5596\n",
      "Epoch 55/1000\n",
      "101/101 [==============================] - 65s 576ms/step - loss: 0.2994 - f1_score: 0.8119 - val_loss: 1.0713 - val_f1_score: 0.5738\n",
      "Epoch 56/1000\n",
      "101/101 [==============================] - 64s 572ms/step - loss: 0.2791 - f1_score: 0.8304 - val_loss: 1.1292 - val_f1_score: 0.5351\n",
      "Epoch 57/1000\n",
      "101/101 [==============================] - 64s 568ms/step - loss: 0.3194 - f1_score: 0.8061 - val_loss: 1.0913 - val_f1_score: 0.5872\n",
      "Epoch 58/1000\n",
      "101/101 [==============================] - 64s 568ms/step - loss: 0.2859 - f1_score: 0.8216 - val_loss: 1.0498 - val_f1_score: 0.6095\n",
      "Epoch 59/1000\n",
      "101/101 [==============================] - 65s 578ms/step - loss: 0.3017 - f1_score: 0.8172 - val_loss: 1.0747 - val_f1_score: 0.5835\n",
      "Epoch 60/1000\n",
      "101/101 [==============================] - 63s 561ms/step - loss: 0.2778 - f1_score: 0.8315 - val_loss: 1.0054 - val_f1_score: 0.6070\n",
      "Epoch 61/1000\n",
      "101/101 [==============================] - 66s 588ms/step - loss: 0.2964 - f1_score: 0.8201 - val_loss: 1.0892 - val_f1_score: 0.5856\n",
      "Epoch 62/1000\n",
      "101/101 [==============================] - 65s 579ms/step - loss: 0.2779 - f1_score: 0.8171 - val_loss: 1.0091 - val_f1_score: 0.6107\n",
      "Epoch 63/1000\n",
      "101/101 [==============================] - 64s 571ms/step - loss: 0.2748 - f1_score: 0.8300 - val_loss: 1.0588 - val_f1_score: 0.6115\n",
      "Epoch 00063: early stopping\n"
     ]
    }
   ],
   "source": [
    "from analysis_tools.modeling import *\n",
    "\n",
    "model, base_model = build_model(n_classes, strategy)\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=1000, callbacks=get_callbacks(patience=30, plot_path=join(PATH.result, 'proposed3', 'fix_pretrained_model_nadam_b7')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4016a27",
   "metadata": {},
   "source": [
    "## 3.2 Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a6cf4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "INFO:tensorflow:batch_all_reduce: 711 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 711 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "4 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[11,32,350,350] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/efficientnetb7/block1c_bn/FusedBatchNormV3 (defined at /threading.py:932) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[div_no_nan_1/ReadVariableOp_2/_1178]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[11,32,350,350] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/efficientnetb7/block1c_bn/FusedBatchNormV3 (defined at /threading.py:932) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (2) Resource exhausted:  OOM when allocating tensor with shape[11,32,350,350] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/efficientnetb7/block1c_bn/FusedBatchNormV3 (defined at /threading.py:932) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[Mean/_1221]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (3) Resource exhausted:  OOM when allocating tensor with shape[11,32,350,350] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/efficientnetb7/block1c_bn/FusedBatchNormV3 (defined at /threading.py:932) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[Nadam/Nadam/group_deps/_1587]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_450246]\n\nFunction call stack:\ntrain_function -> train_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ad4b24e9f529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNadam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mF1Score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'proposed3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fine_tuning_nadam_b7'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 4 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[11,32,350,350] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/efficientnetb7/block1c_bn/FusedBatchNormV3 (defined at /threading.py:932) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[div_no_nan_1/ReadVariableOp_2/_1178]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[11,32,350,350] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/efficientnetb7/block1c_bn/FusedBatchNormV3 (defined at /threading.py:932) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (2) Resource exhausted:  OOM when allocating tensor with shape[11,32,350,350] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/efficientnetb7/block1c_bn/FusedBatchNormV3 (defined at /threading.py:932) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[Mean/_1221]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (3) Resource exhausted:  OOM when allocating tensor with shape[11,32,350,350] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/efficientnetb7/block1c_bn/FusedBatchNormV3 (defined at /threading.py:932) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[Nadam/Nadam/group_deps/_1587]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_450246]\n\nFunction call stack:\ntrain_function -> train_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    base_model.trainable = True\n",
    "    model.compile(optimizer=keras.optimizers.Nadam(2e-4), loss='categorical_crossentropy', metrics=[F1Score(num_classes=n_classes, average='macro')])\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=1000, callbacks=get_callbacks(patience=30, plot_path=join(PATH.result, 'proposed3', 'fine_tuning_nadam_b7')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ec114",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c990309",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file_path = join(PATH.output, 'proposed3_fine_tuning_nadam_b6.csv')\n",
    "\n",
    "pred_test = model.predict(test_ds)\n",
    "submission = pd.read_csv(join(PATH.input, 'sample_submission.csv'), index_col=0)\n",
    "submission['label'] = y_enc.inverse_transform(pred_test)\n",
    "submission.to_csv(submission_file_path)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3912a8",
   "metadata": {},
   "source": [
    "# 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacon_submit_api.dacon_submit_api import post_submission_file\n",
    "\n",
    "result = post_submission_file(\n",
    "    submission_file_path,\n",
    "    '137ff236e305f302819b930b3b5b72e948603f23c5249a516c32b536d5187a03', \n",
    "    '235894', \n",
    "    '어스름한 금요일 밤에', \n",
    "    'proposed3_fine_tuning_nadam_b7'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
