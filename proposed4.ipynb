{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2743d5c",
   "metadata": {},
   "source": [
    "# 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b63b6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    }
   ],
   "source": [
    "from analysis_tools.common import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import sklearn\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "sklearn.random.seed(RANDOM_STATE)\n",
    "\n",
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083ee50",
   "metadata": {},
   "source": [
    "# 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6eba851",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  7.8s\n",
      "[########################################] | 100% Completed |  3.7s\n",
      "- Number of train full data: 4277\n",
      "- Number of test data: 2154\n"
     ]
    }
   ],
   "source": [
    "train_full_data_meta = pd.read_csv(join(PATH.input, 'train_df.csv'), index_col=0)\n",
    "test_data_meta       = pd.read_csv(join(PATH.input, 'test_df.csv'), index_col=0)\n",
    "\n",
    "with ProgressBar():\n",
    "    X_train_full = compute(*[delayed(cv2.imread)(path) for path in ls_file(PATH.train)])\n",
    "    X_test       = compute(*[delayed(cv2.imread)(path) for path in ls_file(PATH.test)])\n",
    "\n",
    "print(\"- Number of train full data:\", len(X_train_full))\n",
    "print(\"- Number of test data:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508182a",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b651f55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2.1s\n",
      "[########################################] | 100% Completed |  0.9s\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE    = 512\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "with ProgressBar():\n",
    "    X_train_full = np.array(compute(*[delayed(cv2.resize)(X, [IMG_SIZE, IMG_SIZE]) for X in X_train_full]))\n",
    "    X_test       = np.array(compute(*[delayed(cv2.resize)(X, [IMG_SIZE, IMG_SIZE]) for X in X_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1dc1350",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aug_model = keras.models.Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "def preprocess(ds, training, batch_size, augment=True):\n",
    "    ds = ds.cache().batch(batch_size)\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=1000).prefetch(tf.data.AUTOTUNE)\n",
    "        if augment:\n",
    "            ds = ds.map(lambda X, y, sw: (aug_model(X), y, sw), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# fig, axes = plt.subplots(5, 15, figsize=(30, 10))\n",
    "# for row, ax_cols in enumerate(axes):\n",
    "#     for ax in ax_cols:\n",
    "#         ax.imshow(aug_model(X_train_full[row]))\n",
    "#         ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d403b",
   "metadata": {},
   "source": [
    "## 3.1 Classification(`class`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e40c24c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train1.shape: (3207, 512, 512, 3) (3207, 15)\n",
      "- val1.shape: (1070, 512, 512, 3) (1070, 15)\n",
      "- test.shape: (2154, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "y_train_full1 = train_full_data_meta[['class']]\n",
    "y_enc1        = OneHotEncoder(sparse=False, dtype=bool)\n",
    "y_train_full1 = y_enc1.fit_transform(y_train_full1)\n",
    "n_classes1    = len(y_enc1.categories_[0])\n",
    "\n",
    "X_train1, X_val1, y_train1, y_val1 = train_test_split(X_train_full, y_train_full1, stratify=y_train_full1)\n",
    "sample_weight_train1 = compute_sample_weight(class_weight='balanced', y=y_train1.argmax(1))\n",
    "sample_weight_val1   = compute_sample_weight(class_weight='balanced', y=y_val1.argmax(1))\n",
    "\n",
    "train_ds1 = preprocess(tf.data.Dataset.from_tensor_slices((X_train1, y_train1, sample_weight_train1)), True, BATCH_SIZE)\n",
    "val_ds1   = preprocess(tf.data.Dataset.from_tensor_slices((X_val1, y_val1, sample_weight_val1)), False, BATCH_SIZE)\n",
    "test_ds1  = preprocess(tf.data.Dataset.from_tensor_slices(X_test), False, BATCH_SIZE)\n",
    "\n",
    "print(\"- train1.shape:\", X_train1.shape, y_train1.shape)\n",
    "print(\"- val1.shape:\", X_val1.shape, y_val1.shape)\n",
    "print(\"- test.shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e1e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.metrics import F1Score\n",
    "\n",
    "def build_model(n_classes, strategy):\n",
    "    def build_fine_tuning_model(model, base_model):\n",
    "        with strategy.scope():\n",
    "            base_model.trainable = True\n",
    "            model.compile(optimizer=keras.optimizers.Adam(2e-4), loss='categorical_crossentropy', metrics=[F1Score(num_classes=n_classes, average='macro')])\n",
    "        return model, base_model\n",
    "        \n",
    "    with strategy.scope():\n",
    "        base_model = keras.applications.EfficientNetB0(include_top=False, input_shape=input_shape)\n",
    "        base_model.trainable = False\n",
    "\n",
    "        inputs  = keras.Input(input_shape)\n",
    "        hidden  = base_model(inputs, training=False)\n",
    "        hidden  = keras.layers.GlobalAveragePooling2D()(hidden)\n",
    "        outputs = keras.layers.Dense(n_classes, activation='softmax')(hidden)\n",
    "        model   = keras.Model(inputs, outputs)\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[F1Score(num_classes=n_classes, average='macro')])\n",
    "    \n",
    "    return model, base_model, build_fine_tuning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5171581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/5\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  5/101 [>.............................] - ETA: 1:18 - loss: 2.5562 - f1_score: 0.1734WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0486s vs `on_train_batch_begin` time: 0.3386s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0486s vs `on_train_batch_end` time: 0.1724s). Check your callbacks.\n",
      "101/101 [==============================] - 43s 192ms/step - loss: 0.4378 - f1_score: 0.9435 - val_loss: 0.0332 - val_f1_score: 1.0000\n",
      "Epoch 2/5\n",
      "101/101 [==============================] - 14s 119ms/step - loss: 0.0221 - f1_score: 1.0000 - val_loss: 0.0136 - val_f1_score: 1.0000\n",
      "Epoch 3/5\n",
      "101/101 [==============================] - 14s 101ms/step - loss: 0.0107 - f1_score: 1.0000 - val_loss: 0.0079 - val_f1_score: 1.0000\n",
      "Epoch 4/5\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.0064 - f1_score: 1.0000 - val_loss: 0.0053 - val_f1_score: 1.0000\n",
      "Epoch 5/5\n",
      "101/101 [==============================] - 13s 98ms/step - loss: 0.0045 - f1_score: 1.0000 - val_loss: 0.0038 - val_f1_score: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc8f0775c10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from analysis_tools.modeling import *\n",
    "\n",
    "model1, base_model1, build_fine_tuning_model1 = build_model(n_classes1, strategy)\n",
    "model1.fit(train_ds1, validation_data=val_ds1, epochs=5, callbacks=get_callbacks(patience=5, plot_path=join(PATH.result, 'proposed4', 'classification_class')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c366ea57",
   "metadata": {},
   "source": [
    "## 3.2 Classification(`label`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5adb572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "      <th>state</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.png</td>\n",
       "      <td>transistor</td>\n",
       "      <td>good</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001.png</td>\n",
       "      <td>capsule</td>\n",
       "      <td>good</td>\n",
       "      <td>capsule-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002.png</td>\n",
       "      <td>transistor</td>\n",
       "      <td>good</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003.png</td>\n",
       "      <td>wood</td>\n",
       "      <td>good</td>\n",
       "      <td>wood-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004.png</td>\n",
       "      <td>bottle</td>\n",
       "      <td>good</td>\n",
       "      <td>bottle-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name       class state            label\n",
       "index                                              \n",
       "0      10000.png  transistor  good  transistor-good\n",
       "1      10001.png     capsule  good     capsule-good\n",
       "2      10002.png  transistor  good  transistor-good\n",
       "3      10003.png        wood  good        wood-good\n",
       "4      10004.png      bottle  good      bottle-good"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_data_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f104ed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:12<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_val2, y_train2, y_val2 = {}, {}, {}, {}\n",
    "y_enc2             = {}\n",
    "n_classes2         = {}\n",
    "train_ds2, val_ds2 = {}, {}\n",
    "for c in tqdm(train_full_data_meta['class'].unique()):\n",
    "    idxs             = train_full_data_meta.query(f\"`class` == '{c}'\").index\n",
    "    X_train_full2    = X_train_full[idxs]\n",
    "\n",
    "    y_enc2[c]        = OneHotEncoder(sparse=False, dtype=bool)\n",
    "    y_train_full2    = y_enc2[c].fit_transform(train_full_data_meta[['label']].loc[idxs])\n",
    "    n_classes2[c]    = len(y_enc2[c].categories_[0])\n",
    "    \n",
    "    X_train2[c], X_val2[c], y_train2[c], y_val2[c] = train_test_split(X_train_full2, y_train_full2, stratify=y_train_full2)\n",
    "    sample_weight_train2 = compute_sample_weight(class_weight='balanced', y=y_train2[c].argmax(1))\n",
    "    sample_weight_val2   = compute_sample_weight(class_weight='balanced', y=y_val2[c].argmax(1))\n",
    "\n",
    "    train_ds2[c] = preprocess(tf.data.Dataset.from_tensor_slices((X_train2[c], y_train2[c], sample_weight_train2)), True, BATCH_SIZE)\n",
    "    val_ds2[c]   = preprocess(tf.data.Dataset.from_tensor_slices((X_val2[c], y_val2[c], sample_weight_val2)), False, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b64471ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6/8 [=====================>........] - ETA: 1s - loss: 2.4021 - f1_score: 0.0252WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0408s vs `on_train_batch_begin` time: 0.2005s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0408s vs `on_train_batch_end` time: 0.2128s). Check your callbacks.\n",
      "8/8 [==============================] - 25s 1s/step - loss: 2.2240 - f1_score: 0.0664 - val_loss: 2.1773 - val_f1_score: 0.1113\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 2s 91ms/step - loss: 2.1361 - f1_score: 0.1374 - val_loss: 2.1244 - val_f1_score: 0.1638\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 2s 90ms/step - loss: 2.0616 - f1_score: 0.0422 - val_loss: 2.0781 - val_f1_score: 0.1124\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 2s 86ms/step - loss: 2.0586 - f1_score: 0.0973 - val_loss: 2.0488 - val_f1_score: 0.3071\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 2s 91ms/step - loss: 2.1065 - f1_score: 0.1380 - val_loss: 2.0332 - val_f1_score: 0.2380\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 2s 88ms/step - loss: 1.9582 - f1_score: 0.2631 - val_loss: 2.0024 - val_f1_score: 0.2142\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 2s 92ms/step - loss: 1.9663 - f1_score: 0.1579 - val_loss: 2.0059 - val_f1_score: 0.0355\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.9281 - f1_score: 0.1356 - val_loss: 2.0430 - val_f1_score: 0.0627\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 2s 99ms/step - loss: 1.9759 - f1_score: 0.1704 - val_loss: 2.0505 - val_f1_score: 0.1878\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 2s 97ms/step - loss: 1.9408 - f1_score: 0.2858 - val_loss: 2.0038 - val_f1_score: 0.1933\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 2s 98ms/step - loss: 1.9253 - f1_score: 0.3355 - val_loss: 1.9656 - val_f1_score: 0.3133\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 2s 93ms/step - loss: 1.8884 - f1_score: 0.2788 - val_loss: 1.9418 - val_f1_score: 0.2614\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 2s 96ms/step - loss: 1.8147 - f1_score: 0.3567 - val_loss: 1.8963 - val_f1_score: 0.2655\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 2s 97ms/step - loss: 1.8279 - f1_score: 0.3348 - val_loss: 1.8825 - val_f1_score: 0.2471\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 2s 96ms/step - loss: 1.8034 - f1_score: 0.3129 - val_loss: 1.8865 - val_f1_score: 0.4005\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 2s 98ms/step - loss: 1.8011 - f1_score: 0.3346 - val_loss: 1.8842 - val_f1_score: 0.3638\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 2s 97ms/step - loss: 1.7884 - f1_score: 0.2759 - val_loss: 1.8823 - val_f1_score: 0.1827\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 2s 97ms/step - loss: 1.7759 - f1_score: 0.2411 - val_loss: 1.8679 - val_f1_score: 0.2471\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 2s 101ms/step - loss: 1.7249 - f1_score: 0.4106 - val_loss: 1.8634 - val_f1_score: 0.2655\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 2s 94ms/step - loss: 1.7214 - f1_score: 0.3576 - val_loss: 1.8071 - val_f1_score: 0.4464\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 2s 98ms/step - loss: 1.7120 - f1_score: 0.3072 - val_loss: 1.7973 - val_f1_score: 0.4967\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 2s 97ms/step - loss: 1.7275 - f1_score: 0.4152 - val_loss: 1.8183 - val_f1_score: 0.4098\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 2s 98ms/step - loss: 1.7558 - f1_score: 0.3313 - val_loss: 1.8018 - val_f1_score: 0.2814\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 2s 97ms/step - loss: 1.6876 - f1_score: 0.4648 - val_loss: 1.7699 - val_f1_score: 0.3309\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 2s 93ms/step - loss: 1.6488 - f1_score: 0.4721 - val_loss: 1.7659 - val_f1_score: 0.3722\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 2s 94ms/step - loss: 1.7395 - f1_score: 0.3612 - val_loss: 1.7693 - val_f1_score: 0.2865\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 2s 96ms/step - loss: 1.6632 - f1_score: 0.3748 - val_loss: 1.7827 - val_f1_score: 0.2498\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 2s 97ms/step - loss: 1.6078 - f1_score: 0.4846 - val_loss: 1.7553 - val_f1_score: 0.5403\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 2s 94ms/step - loss: 1.5710 - f1_score: 0.4954 - val_loss: 1.7795 - val_f1_score: 0.4570\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 2s 95ms/step - loss: 1.5863 - f1_score: 0.4666 - val_loss: 1.7859 - val_f1_score: 0.4552\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 2s 90ms/step - loss: 1.6311 - f1_score: 0.4269 - val_loss: 1.7466 - val_f1_score: 0.3301\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 2s 91ms/step - loss: 1.5715 - f1_score: 0.4297 - val_loss: 1.7414 - val_f1_score: 0.3685\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 2s 94ms/step - loss: 1.5765 - f1_score: 0.4399 - val_loss: 1.7413 - val_f1_score: 0.3002\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 2s 91ms/step - loss: 1.6148 - f1_score: 0.3473 - val_loss: 1.7440 - val_f1_score: 0.2617\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 1.5439 - f1_score: 0.4801 - val_loss: 1.7346 - val_f1_score: 0.3176\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 2s 89ms/step - loss: 1.5285 - f1_score: 0.5058 - val_loss: 1.7266 - val_f1_score: 0.3380\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 2s 89ms/step - loss: 1.5489 - f1_score: 0.4620 - val_loss: 1.6956 - val_f1_score: 0.3380\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 2s 100ms/step - loss: 1.4926 - f1_score: 0.5183 - val_loss: 1.6816 - val_f1_score: 0.5787\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 2s 94ms/step - loss: 1.4946 - f1_score: 0.4410 - val_loss: 1.6651 - val_f1_score: 0.5148\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 2s 97ms/step - loss: 1.4942 - f1_score: 0.4904 - val_loss: 1.6606 - val_f1_score: 0.4676\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 2s 91ms/step - loss: 1.5127 - f1_score: 0.5479 - val_loss: 1.6450 - val_f1_score: 0.4179\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 2s 92ms/step - loss: 1.5137 - f1_score: 0.4925 - val_loss: 1.6347 - val_f1_score: 0.3827\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 2s 89ms/step - loss: 1.5117 - f1_score: 0.3994 - val_loss: 1.6394 - val_f1_score: 0.2257\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 2s 88ms/step - loss: 1.5123 - f1_score: 0.4175 - val_loss: 1.6413 - val_f1_score: 0.2417\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 1.4976 - f1_score: 0.5359 - val_loss: 1.6313 - val_f1_score: 0.3940\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 2s 91ms/step - loss: 1.4670 - f1_score: 0.5342 - val_loss: 1.6357 - val_f1_score: 0.3171\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 2s 90ms/step - loss: 1.4473 - f1_score: 0.4851 - val_loss: 1.6308 - val_f1_score: 0.3320\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 2s 87ms/step - loss: 1.4617 - f1_score: 0.5537 - val_loss: 1.6402 - val_f1_score: 0.3126\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 2s 89ms/step - loss: 1.3800 - f1_score: 0.4419 - val_loss: 1.6799 - val_f1_score: 0.3231\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 2s 243ms/step - loss: 1.5035 - f1_score: 0.5068 - val_loss: 1.6446 - val_f1_score: 0.3087\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 2s 88ms/step - loss: 1.3848 - f1_score: 0.5039 - val_loss: 1.5945 - val_f1_score: 0.3320\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 2s 89ms/step - loss: 1.4202 - f1_score: 0.4734 - val_loss: 1.6051 - val_f1_score: 0.3231\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 2s 88ms/step - loss: 1.4444 - f1_score: 0.4660 - val_loss: 1.6286 - val_f1_score: 0.2894\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 2s 88ms/step - loss: 1.4735 - f1_score: 0.4513 - val_loss: 1.6067 - val_f1_score: 0.4158\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 2s 86ms/step - loss: 1.4437 - f1_score: 0.4168 - val_loss: 1.6122 - val_f1_score: 0.2986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 1.3287 - f1_score: 0.5910 - val_loss: 1.6062 - val_f1_score: 0.3786\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 2s 87ms/step - loss: 1.3471 - f1_score: 0.5379 - val_loss: 1.6238 - val_f1_score: 0.2786\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 2s 88ms/step - loss: 1.4198 - f1_score: 0.4392 - val_loss: 1.6079 - val_f1_score: 0.3718\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 2s 91ms/step - loss: 1.4267 - f1_score: 0.4074 - val_loss: 1.5932 - val_f1_score: 0.4552\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 2s 91ms/step - loss: 1.3811 - f1_score: 0.5047 - val_loss: 1.5735 - val_f1_score: 0.4570\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 2s 90ms/step - loss: 1.4043 - f1_score: 0.6184 - val_loss: 1.5702 - val_f1_score: 0.4991\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 2s 88ms/step - loss: 1.3642 - f1_score: 0.4967 - val_loss: 1.5784 - val_f1_score: 0.3822\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 2s 91ms/step - loss: 1.2940 - f1_score: 0.6311 - val_loss: 1.5825 - val_f1_score: 0.3181\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 2s 87ms/step - loss: 1.2609 - f1_score: 0.6328 - val_loss: 1.6134 - val_f1_score: 0.4144\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 2s 93ms/step - loss: 1.2922 - f1_score: 0.5874 - val_loss: 1.6138 - val_f1_score: 0.3865\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 2s 89ms/step - loss: 1.3296 - f1_score: 0.5142 - val_loss: 1.6484 - val_f1_score: 0.2311\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 2s 94ms/step - loss: 1.3581 - f1_score: 0.4732 - val_loss: 1.6230 - val_f1_score: 0.2684\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 2s 247ms/step - loss: 1.3609 - f1_score: 0.5627 - val_loss: 1.6046 - val_f1_score: 0.3002\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 2s 89ms/step - loss: 1.3268 - f1_score: 0.5294 - val_loss: 1.6182 - val_f1_score: 0.3577\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 2s 91ms/step - loss: 1.2812 - f1_score: 0.5529 - val_loss: 1.6540 - val_f1_score: 0.3078\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 2s 90ms/step - loss: 1.2828 - f1_score: 0.5840 - val_loss: 1.6592 - val_f1_score: 0.3822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [03:30<00:00, 14.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00071: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = {}\n",
    "for c in tqdm(train_full_data_meta['class'].unique()):\n",
    "    if c != 'zipper':\n",
    "        continue\n",
    "        \n",
    "    model2[c], base_model2, build_fine_tuning_model2 = build_model(n_classes2[c], strategy)\n",
    "    model2[c].fit(train_ds2[c], validation_data=val_ds2[c], epochs=1000, callbacks=get_callbacks(patience=10, plot_path=join(PATH.result, 'proposed4', f'classification_label_{c}')))\n",
    "    if c != 'zipper':  # 'zipper': fine tuning is not good (why?)\n",
    "        model2[c], base_model2 = build_fine_tuning_model2(model2[c], base_model2)\n",
    "        model2[c].fit(train_ds2[c], validation_data=val_ds2[c], epochs=1000, callbacks=get_callbacks(patience=10, plot_path=join(PATH.result, 'proposed4', f'classification_label_fine_tuning_{c}')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ec114",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e229b676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  label\n",
       "index                  \n",
       "0       tile-glue_strip\n",
       "1             grid-good\n",
       "2       transistor-good\n",
       "3      tile-gray_stroke\n",
       "4             tile-good\n",
       "...                 ...\n",
       "2149   tile-gray_stroke\n",
       "2150         screw-good\n",
       "2151          grid-good\n",
       "2152         cable-good\n",
       "2153        zipper-good\n",
       "\n",
       "[2154 rows x 1 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission           = pd.read_csv(join(PATH.input, 'sample_submission.csv'), index_col=0)\n",
    "submission_file_path = join(PATH.output, 'proposed4.csv')\n",
    "\n",
    "pred_test1_oh  = model1.predict(test_ds1)                 # class(int)\n",
    "pred_test1_str = y_enc1.inverse_transform(pred_test1_oh)  # class(str)\n",
    "for c in tqdm(np.unique(pred_test1_str)):\n",
    "    idxs = np.where(pred_test1_str == c)[0]\n",
    "    X_c  = X_test[idxs]\n",
    "    pred_test2_oh                 = model2[c].predict(X_c)\n",
    "    submission.loc[idxs, 'label'] = y_enc2[c].inverse_transform(pred_test2_oh).flatten()\n",
    "\n",
    "submission.to_csv(submission_file_path)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3912a8",
   "metadata": {},
   "source": [
    "# 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb4c06fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': True, 'detail': 'Success'}\n"
     ]
    }
   ],
   "source": [
    "from dacon_submit_api.dacon_submit_api import post_submission_file\n",
    "\n",
    "result = post_submission_file(\n",
    "    submission_file_path,\n",
    "    '137ff236e305f302819b930b3b5b72e948603f23c5249a516c32b536d5187a03', \n",
    "    '235894',\n",
    "    '어스름한 금요일 밤에',\n",
    "    get_name(submission_file_path)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
