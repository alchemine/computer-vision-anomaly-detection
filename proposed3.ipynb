{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2743d5c",
   "metadata": {},
   "source": [
    "# 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b63b6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    }
   ],
   "source": [
    "from analysis_tools.common import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import sklearn\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "sklearn.random.seed(RANDOM_STATE)\n",
    "\n",
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083ee50",
   "metadata": {},
   "source": [
    "# 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6eba851",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  7.7s\n",
      "[########################################] | 100% Completed |  3.6s\n",
      "- Number of train full data: 4277\n",
      "- Number of test data: 2154\n"
     ]
    }
   ],
   "source": [
    "train_full_data_meta = pd.read_csv(join(PATH.input, 'train_df.csv'), index_col=0)\n",
    "test_data_meta       = pd.read_csv(join(PATH.input, 'test_df.csv'), index_col=0)\n",
    "\n",
    "with ProgressBar():\n",
    "    X_train_full = compute(*[delayed(cv2.imread)(path) for path in ls_file(PATH.train)])\n",
    "    X_test       = compute(*[delayed(cv2.imread)(path) for path in ls_file(PATH.test)])\n",
    "y_train_full = train_full_data_meta[['label']]\n",
    "    \n",
    "print(\"- Number of train full data:\", len(X_train_full))\n",
    "print(\"- Number of test data:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508182a",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e372118e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of classes: 88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "IMG_SIZE    = 512\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "with ProgressBar():\n",
    "    X_train_full = np.array(compute(*[delayed(cv2.resize)(X, [IMG_SIZE, IMG_SIZE]) for X in X_train_full]))\n",
    "    X_test       = np.array(compute(*[delayed(cv2.resize)(X, [IMG_SIZE, IMG_SIZE]) for X in X_test]))\n",
    "y_enc = OneHotEncoder(sparse=False, dtype=bool)\n",
    "y_train_full = y_enc.fit_transform(y_train_full)\n",
    "n_classes = len(y_enc.categories_[0])\n",
    "print(\"- Number of classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe1d1139",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aug_model = keras.models.Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "def preprocess(ds, training, batch_size, augment=True):\n",
    "    ds = ds.cache().batch(batch_size)\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=1000).prefetch(tf.data.AUTOTUNE)\n",
    "        if augment:\n",
    "            ds = ds.map(lambda X, y, sw: (aug_model(X), y, sw), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# fig, axes = plt.subplots(5, 15, figsize=(30, 10))\n",
    "# for row, ax_cols in enumerate(axes):\n",
    "#     for ax in ax_cols:\n",
    "#         ax.imshow(aug_model(X_train_full[row]))\n",
    "#         ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20862d",
   "metadata": {},
   "source": [
    "## 3.1 Fix pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef44e53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train.shape: (3207, 512, 512, 3) (3207, 88)\n",
      "- val.shape: (1070, 512, 512, 3) (1070, 88)\n",
      "- test.shape: (2154, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, stratify=y_train_full)\n",
    "sample_weight_train = compute_sample_weight(class_weight='balanced', y=y_train.argmax(1))\n",
    "sample_weight_val   = compute_sample_weight(class_weight='balanced', y=y_val.argmax(1))\n",
    "\n",
    "train_ds = preprocess(tf.data.Dataset.from_tensor_slices((X_train, y_train, sample_weight_train)), True, BATCH_SIZE)\n",
    "val_ds   = preprocess(tf.data.Dataset.from_tensor_slices((X_val, y_val, sample_weight_val)), False, BATCH_SIZE)\n",
    "test_ds  = preprocess(tf.data.Dataset.from_tensor_slices(X_test), False, BATCH_SIZE)\n",
    "\n",
    "print(\"- train.shape:\", X_train.shape, y_train.shape)\n",
    "print(\"- val.shape:\", X_val.shape, y_val.shape)\n",
    "print(\"- test.shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9e1e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.metrics import F1Score\n",
    "\n",
    "def build_model(n_classes, strategy):\n",
    "    with strategy.scope():\n",
    "        base_model = keras.applications.EfficientNetB0(include_top=False, input_shape=input_shape)\n",
    "        base_model.trainable = False\n",
    "\n",
    "        inputs  = keras.Input(input_shape)\n",
    "        hidden  = base_model(inputs, training=False)\n",
    "        hidden  = keras.layers.GlobalAveragePooling2D()(hidden)\n",
    "        outputs = keras.layers.Dense(n_classes, activation='softmax')(hidden)\n",
    "        model   = keras.Model(inputs, outputs)\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[F1Score(num_classes=n_classes, average='macro')])\n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5171581e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/1000\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  6/101 [>.............................] - ETA: 1:07 - loss: 4.8847 - f1_score: 0.0397WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0566s vs `on_train_batch_begin` time: 0.3653s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0566s vs `on_train_batch_end` time: 0.1775s). Check your callbacks.\n",
      "101/101 [==============================] - 44s 194ms/step - loss: 3.2644 - f1_score: 0.1563 - val_loss: 2.1519 - val_f1_score: 0.1274\n",
      "Epoch 2/1000\n",
      "101/101 [==============================] - 14s 109ms/step - loss: 1.9707 - f1_score: 0.2117 - val_loss: 1.8085 - val_f1_score: 0.1958\n",
      "Epoch 3/1000\n",
      "101/101 [==============================] - 14s 102ms/step - loss: 1.7008 - f1_score: 0.2795 - val_loss: 1.6701 - val_f1_score: 0.2924\n",
      "Epoch 4/1000\n",
      "101/101 [==============================] - 15s 112ms/step - loss: 1.5499 - f1_score: 0.3179 - val_loss: 1.5634 - val_f1_score: 0.3358\n",
      "Epoch 5/1000\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 1.4035 - f1_score: 0.4024 - val_loss: 1.5134 - val_f1_score: 0.3236\n",
      "Epoch 6/1000\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 1.3191 - f1_score: 0.4021 - val_loss: 1.4567 - val_f1_score: 0.3354\n",
      "Epoch 7/1000\n",
      "101/101 [==============================] - 13s 101ms/step - loss: 1.2671 - f1_score: 0.4253 - val_loss: 1.4368 - val_f1_score: 0.3425\n",
      "Epoch 8/1000\n",
      "101/101 [==============================] - 13s 102ms/step - loss: 1.1991 - f1_score: 0.4476 - val_loss: 1.4108 - val_f1_score: 0.3721\n",
      "Epoch 9/1000\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 1.1273 - f1_score: 0.5054 - val_loss: 1.3148 - val_f1_score: 0.4079\n",
      "Epoch 10/1000\n",
      "101/101 [==============================] - 14s 108ms/step - loss: 1.0851 - f1_score: 0.4943 - val_loss: 1.3201 - val_f1_score: 0.4302\n",
      "Epoch 11/1000\n",
      "101/101 [==============================] - 14s 101ms/step - loss: 1.0519 - f1_score: 0.5257 - val_loss: 1.2759 - val_f1_score: 0.4470\n",
      "Epoch 12/1000\n",
      "101/101 [==============================] - 13s 103ms/step - loss: 1.0033 - f1_score: 0.5299 - val_loss: 1.2539 - val_f1_score: 0.4256\n",
      "Epoch 13/1000\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.9499 - f1_score: 0.5622 - val_loss: 1.2071 - val_f1_score: 0.4650\n",
      "Epoch 14/1000\n",
      "101/101 [==============================] - 14s 102ms/step - loss: 0.9152 - f1_score: 0.5808 - val_loss: 1.2775 - val_f1_score: 0.3982\n",
      "Epoch 15/1000\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.9112 - f1_score: 0.5541 - val_loss: 1.1647 - val_f1_score: 0.4939\n",
      "Epoch 16/1000\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.8553 - f1_score: 0.6085 - val_loss: 1.1955 - val_f1_score: 0.4684\n",
      "Epoch 17/1000\n",
      "101/101 [==============================] - 13s 101ms/step - loss: 0.8553 - f1_score: 0.5977 - val_loss: 1.1858 - val_f1_score: 0.4628\n",
      "Epoch 18/1000\n",
      "101/101 [==============================] - 14s 100ms/step - loss: 0.8390 - f1_score: 0.6048 - val_loss: 1.1577 - val_f1_score: 0.4462\n",
      "Epoch 19/1000\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.8130 - f1_score: 0.6009 - val_loss: 1.1229 - val_f1_score: 0.4535\n",
      "Epoch 20/1000\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.8023 - f1_score: 0.6184 - val_loss: 1.1354 - val_f1_score: 0.4617\n",
      "Epoch 21/1000\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.7520 - f1_score: 0.6200 - val_loss: 1.1251 - val_f1_score: 0.4832\n",
      "Epoch 22/1000\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.7384 - f1_score: 0.6607 - val_loss: 1.1701 - val_f1_score: 0.4451\n",
      "Epoch 23/1000\n",
      "101/101 [==============================] - 14s 100ms/step - loss: 0.7257 - f1_score: 0.6562 - val_loss: 1.1657 - val_f1_score: 0.4730\n",
      "Epoch 24/1000\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.7129 - f1_score: 0.6693 - val_loss: 1.1078 - val_f1_score: 0.5179\n",
      "Epoch 25/1000\n",
      "101/101 [==============================] - 14s 102ms/step - loss: 0.7073 - f1_score: 0.6542 - val_loss: 1.1307 - val_f1_score: 0.4784\n",
      "Epoch 26/1000\n",
      "101/101 [==============================] - 13s 111ms/step - loss: 0.6782 - f1_score: 0.6608 - val_loss: 1.1628 - val_f1_score: 0.4716\n",
      "Epoch 27/1000\n",
      "101/101 [==============================] - 13s 98ms/step - loss: 0.6786 - f1_score: 0.6555 - val_loss: 1.1314 - val_f1_score: 0.4499\n",
      "Epoch 28/1000\n",
      "101/101 [==============================] - 14s 102ms/step - loss: 0.6523 - f1_score: 0.6774 - val_loss: 1.0863 - val_f1_score: 0.4892\n",
      "Epoch 29/1000\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.6559 - f1_score: 0.6580 - val_loss: 1.1086 - val_f1_score: 0.4803\n",
      "Epoch 30/1000\n",
      "101/101 [==============================] - 12s 107ms/step - loss: 0.6599 - f1_score: 0.6751 - val_loss: 1.0713 - val_f1_score: 0.5430\n",
      "Epoch 31/1000\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.6040 - f1_score: 0.6790 - val_loss: 1.0738 - val_f1_score: 0.5059\n",
      "Epoch 32/1000\n",
      "101/101 [==============================] - 14s 101ms/step - loss: 0.6170 - f1_score: 0.6891 - val_loss: 1.0985 - val_f1_score: 0.5228\n",
      "Epoch 33/1000\n",
      "101/101 [==============================] - 12s 101ms/step - loss: 0.5942 - f1_score: 0.6995 - val_loss: 1.0388 - val_f1_score: 0.5373\n",
      "Epoch 34/1000\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.5928 - f1_score: 0.7095 - val_loss: 1.1037 - val_f1_score: 0.5028\n",
      "Epoch 35/1000\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.5695 - f1_score: 0.7167 - val_loss: 1.0973 - val_f1_score: 0.4612\n",
      "Epoch 36/1000\n",
      "101/101 [==============================] - 12s 102ms/step - loss: 0.5876 - f1_score: 0.6826 - val_loss: 1.1161 - val_f1_score: 0.4979\n",
      "Epoch 37/1000\n",
      "101/101 [==============================] - 13s 103ms/step - loss: 0.5425 - f1_score: 0.7221 - val_loss: 1.0730 - val_f1_score: 0.4924\n",
      "Epoch 38/1000\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.5583 - f1_score: 0.7023 - val_loss: 1.0938 - val_f1_score: 0.5558\n",
      "Epoch 39/1000\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.5450 - f1_score: 0.7187 - val_loss: 1.0798 - val_f1_score: 0.4985\n",
      "Epoch 40/1000\n",
      "101/101 [==============================] - 15s 113ms/step - loss: 0.5457 - f1_score: 0.7089 - val_loss: 1.0334 - val_f1_score: 0.5664\n",
      "Epoch 41/1000\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.5337 - f1_score: 0.7172 - val_loss: 1.0550 - val_f1_score: 0.5439\n",
      "Epoch 42/1000\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.5222 - f1_score: 0.7283 - val_loss: 1.0466 - val_f1_score: 0.5199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "101/101 [==============================] - 14s 99ms/step - loss: 0.5008 - f1_score: 0.7246 - val_loss: 1.0357 - val_f1_score: 0.5354\n",
      "Epoch 44/1000\n",
      "101/101 [==============================] - 14s 108ms/step - loss: 0.5069 - f1_score: 0.7441 - val_loss: 1.0355 - val_f1_score: 0.5706\n",
      "Epoch 45/1000\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.5050 - f1_score: 0.7346 - val_loss: 1.0250 - val_f1_score: 0.5002\n",
      "Epoch 46/1000\n",
      "101/101 [==============================] - 14s 102ms/step - loss: 0.4773 - f1_score: 0.7399 - val_loss: 1.0803 - val_f1_score: 0.4952\n",
      "Epoch 47/1000\n",
      "101/101 [==============================] - 13s 103ms/step - loss: 0.4916 - f1_score: 0.7309 - val_loss: 1.1168 - val_f1_score: 0.5067\n",
      "Epoch 48/1000\n",
      "101/101 [==============================] - 14s 112ms/step - loss: 0.4867 - f1_score: 0.7307 - val_loss: 1.0167 - val_f1_score: 0.5581\n",
      "Epoch 49/1000\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.4894 - f1_score: 0.7354 - val_loss: 1.0356 - val_f1_score: 0.5334\n",
      "Epoch 50/1000\n",
      "101/101 [==============================] - 13s 101ms/step - loss: 0.4741 - f1_score: 0.7451 - val_loss: 1.0131 - val_f1_score: 0.5569\n",
      "Epoch 51/1000\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.4745 - f1_score: 0.7369 - val_loss: 1.0137 - val_f1_score: 0.5276\n",
      "Epoch 52/1000\n",
      "101/101 [==============================] - 13s 101ms/step - loss: 0.4448 - f1_score: 0.7591 - val_loss: 1.0089 - val_f1_score: 0.5674\n",
      "Epoch 53/1000\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.4418 - f1_score: 0.7358 - val_loss: 1.0813 - val_f1_score: 0.5250\n",
      "Epoch 54/1000\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.4440 - f1_score: 0.7640 - val_loss: 1.0447 - val_f1_score: 0.5797\n",
      "Epoch 55/1000\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.4618 - f1_score: 0.7561 - val_loss: 1.0616 - val_f1_score: 0.5384\n",
      "Epoch 56/1000\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.4551 - f1_score: 0.7365 - val_loss: 1.0247 - val_f1_score: 0.5222\n",
      "Epoch 57/1000\n",
      "101/101 [==============================] - 12s 101ms/step - loss: 0.4283 - f1_score: 0.7719 - val_loss: 1.0323 - val_f1_score: 0.5664\n",
      "Epoch 58/1000\n",
      "101/101 [==============================] - 13s 103ms/step - loss: 0.4133 - f1_score: 0.7808 - val_loss: 0.9885 - val_f1_score: 0.5786\n",
      "Epoch 59/1000\n",
      "101/101 [==============================] - 12s 101ms/step - loss: 0.3999 - f1_score: 0.7829 - val_loss: 1.0367 - val_f1_score: 0.5392\n",
      "Epoch 60/1000\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.3949 - f1_score: 0.7670 - val_loss: 1.0236 - val_f1_score: 0.5314\n",
      "Epoch 61/1000\n",
      "101/101 [==============================] - 12s 101ms/step - loss: 0.4050 - f1_score: 0.7926 - val_loss: 1.0429 - val_f1_score: 0.5582\n",
      "Epoch 62/1000\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.3784 - f1_score: 0.7706 - val_loss: 1.0426 - val_f1_score: 0.5743\n",
      "Epoch 63/1000\n",
      "101/101 [==============================] - 14s 101ms/step - loss: 0.4081 - f1_score: 0.7668 - val_loss: 1.0559 - val_f1_score: 0.5639\n",
      "Epoch 64/1000\n",
      "101/101 [==============================] - 14s 115ms/step - loss: 0.3985 - f1_score: 0.7759 - val_loss: 1.0389 - val_f1_score: 0.5375\n",
      "Epoch 65/1000\n",
      "101/101 [==============================] - 13s 101ms/step - loss: 0.3926 - f1_score: 0.7726 - val_loss: 1.0631 - val_f1_score: 0.5755\n",
      "Epoch 66/1000\n",
      "101/101 [==============================] - 13s 102ms/step - loss: 0.3794 - f1_score: 0.7939 - val_loss: 1.1036 - val_f1_score: 0.5381\n",
      "Epoch 67/1000\n",
      "101/101 [==============================] - 12s 101ms/step - loss: 0.3885 - f1_score: 0.7981 - val_loss: 1.0574 - val_f1_score: 0.5439\n",
      "Epoch 68/1000\n",
      "101/101 [==============================] - 13s 103ms/step - loss: 0.3938 - f1_score: 0.7718 - val_loss: 1.0265 - val_f1_score: 0.5590\n",
      "Epoch 00068: early stopping\n"
     ]
    }
   ],
   "source": [
    "from analysis_tools.modeling import *\n",
    "\n",
    "model, base_model = build_model(n_classes, strategy)\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=1000, callbacks=get_callbacks(patience=10, plot_path=join(PATH.result, 'proposed3', 'fix_pretrained_model')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ab5950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': True, 'detail': 'Success'}\n"
     ]
    }
   ],
   "source": [
    "from dacon_submit_api.dacon_submit_api import post_submission_file\n",
    "\n",
    "submission_file_path = join(PATH.output, 'proposed3_no_fine_tuning.csv')\n",
    "\n",
    "pred_test = model.predict(test_ds)\n",
    "submission = pd.read_csv(join(PATH.input, 'sample_submission.csv'), index_col=0)\n",
    "submission['label'] = y_enc.inverse_transform(pred_test)\n",
    "submission.to_csv(submission_file_path)\n",
    "\n",
    "result = post_submission_file(\n",
    "    submission_file_path,\n",
    "    '137ff236e305f302819b930b3b5b72e948603f23c5249a516c32b536d5187a03', \n",
    "    '235894', \n",
    "    '어스름한 금요일 밤에', \n",
    "    'proposed3_no_fine_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4016a27",
   "metadata": {},
   "source": [
    "## 3.2 Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a6cf4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  6/101 [>.............................] - ETA: 2:23 - loss: 2.1107 - f1_score: 0.2338WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.3192s vs `on_train_batch_begin` time: 0.3542s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3192s vs `on_train_batch_end` time: 0.6427s). Check your callbacks.\n",
      "101/101 [==============================] - 81s 481ms/step - loss: 1.7682 - f1_score: 0.3840 - val_loss: 1.4050 - val_f1_score: 0.4436\n",
      "Epoch 2/1000\n",
      "101/101 [==============================] - 39s 357ms/step - loss: 1.0444 - f1_score: 0.5215 - val_loss: 1.6742 - val_f1_score: 0.4517\n",
      "Epoch 3/1000\n",
      "101/101 [==============================] - 39s 354ms/step - loss: 0.7984 - f1_score: 0.5914 - val_loss: 1.3156 - val_f1_score: 0.5347\n",
      "Epoch 4/1000\n",
      "101/101 [==============================] - 40s 363ms/step - loss: 0.6975 - f1_score: 0.6360 - val_loss: 1.3943 - val_f1_score: 0.5822\n",
      "Epoch 5/1000\n",
      "101/101 [==============================] - 39s 353ms/step - loss: 0.6744 - f1_score: 0.6618 - val_loss: 1.1686 - val_f1_score: 0.5656\n",
      "Epoch 6/1000\n",
      "101/101 [==============================] - 37s 352ms/step - loss: 0.5207 - f1_score: 0.7048 - val_loss: 1.1813 - val_f1_score: 0.5678\n",
      "Epoch 7/1000\n",
      "101/101 [==============================] - 40s 354ms/step - loss: 0.4914 - f1_score: 0.7155 - val_loss: 1.0473 - val_f1_score: 0.6525\n",
      "Epoch 8/1000\n",
      "101/101 [==============================] - 38s 353ms/step - loss: 0.3903 - f1_score: 0.7587 - val_loss: 1.0473 - val_f1_score: 0.6200\n",
      "Epoch 9/1000\n",
      "101/101 [==============================] - 39s 355ms/step - loss: 0.2922 - f1_score: 0.8074 - val_loss: 1.0518 - val_f1_score: 0.6425\n",
      "Epoch 10/1000\n",
      "101/101 [==============================] - 38s 349ms/step - loss: 0.3134 - f1_score: 0.8123 - val_loss: 0.9754 - val_f1_score: 0.6996\n",
      "Epoch 11/1000\n",
      "101/101 [==============================] - 37s 352ms/step - loss: 0.2808 - f1_score: 0.8073 - val_loss: 0.9679 - val_f1_score: 0.6875\n",
      "Epoch 12/1000\n",
      "101/101 [==============================] - 39s 355ms/step - loss: 0.3040 - f1_score: 0.8091 - val_loss: 0.9393 - val_f1_score: 0.7262\n",
      "Epoch 13/1000\n",
      "101/101 [==============================] - 37s 344ms/step - loss: 0.2302 - f1_score: 0.8403 - val_loss: 0.8029 - val_f1_score: 0.7060\n",
      "Epoch 14/1000\n",
      "101/101 [==============================] - 38s 349ms/step - loss: 0.1469 - f1_score: 0.8840 - val_loss: 1.1576 - val_f1_score: 0.6994\n",
      "Epoch 15/1000\n",
      "101/101 [==============================] - 36s 335ms/step - loss: 0.1920 - f1_score: 0.8766 - val_loss: 0.8492 - val_f1_score: 0.7391\n",
      "Epoch 16/1000\n",
      "101/101 [==============================] - 37s 337ms/step - loss: 0.1025 - f1_score: 0.9166 - val_loss: 1.2232 - val_f1_score: 0.6800\n",
      "Epoch 17/1000\n",
      "101/101 [==============================] - 38s 346ms/step - loss: 0.1773 - f1_score: 0.8734 - val_loss: 1.0948 - val_f1_score: 0.6917\n",
      "Epoch 18/1000\n",
      "101/101 [==============================] - 38s 340ms/step - loss: 0.1281 - f1_score: 0.9160 - val_loss: 0.9089 - val_f1_score: 0.7638\n",
      "Epoch 19/1000\n",
      "101/101 [==============================] - 37s 335ms/step - loss: 0.1965 - f1_score: 0.8892 - val_loss: 0.9215 - val_f1_score: 0.7340\n",
      "Epoch 20/1000\n",
      "101/101 [==============================] - 37s 334ms/step - loss: 0.2015 - f1_score: 0.8863 - val_loss: 0.8998 - val_f1_score: 0.7606\n",
      "Epoch 21/1000\n",
      "101/101 [==============================] - 37s 335ms/step - loss: 0.1426 - f1_score: 0.9096 - val_loss: 0.7447 - val_f1_score: 0.7674\n",
      "Epoch 22/1000\n",
      "101/101 [==============================] - 37s 334ms/step - loss: 0.1512 - f1_score: 0.8943 - val_loss: 0.9438 - val_f1_score: 0.7926\n",
      "Epoch 23/1000\n",
      "101/101 [==============================] - 37s 338ms/step - loss: 0.0595 - f1_score: 0.9429 - val_loss: 1.0924 - val_f1_score: 0.7581\n",
      "Epoch 24/1000\n",
      "101/101 [==============================] - 38s 347ms/step - loss: 0.0794 - f1_score: 0.9408 - val_loss: 0.6871 - val_f1_score: 0.8063\n",
      "Epoch 25/1000\n",
      "101/101 [==============================] - 35s 331ms/step - loss: 0.0883 - f1_score: 0.9308 - val_loss: 1.1614 - val_f1_score: 0.7233\n",
      "Epoch 26/1000\n",
      "101/101 [==============================] - 37s 328ms/step - loss: 0.2295 - f1_score: 0.8837 - val_loss: 1.4304 - val_f1_score: 0.6780\n",
      "Epoch 27/1000\n",
      "101/101 [==============================] - 37s 330ms/step - loss: 0.2437 - f1_score: 0.8570 - val_loss: 0.8286 - val_f1_score: 0.7204\n",
      "Epoch 28/1000\n",
      "101/101 [==============================] - 36s 334ms/step - loss: 0.1501 - f1_score: 0.8943 - val_loss: 1.1184 - val_f1_score: 0.7324\n",
      "Epoch 29/1000\n",
      "101/101 [==============================] - 36s 333ms/step - loss: 0.0793 - f1_score: 0.9285 - val_loss: 1.0083 - val_f1_score: 0.7561\n",
      "Epoch 30/1000\n",
      "101/101 [==============================] - 37s 335ms/step - loss: 0.0528 - f1_score: 0.9444 - val_loss: 0.9190 - val_f1_score: 0.7638\n",
      "Epoch 31/1000\n",
      "101/101 [==============================] - 36s 335ms/step - loss: 0.0477 - f1_score: 0.9586 - val_loss: 1.1293 - val_f1_score: 0.7636\n",
      "Epoch 32/1000\n",
      "101/101 [==============================] - 36s 334ms/step - loss: 0.0757 - f1_score: 0.9507 - val_loss: 0.8929 - val_f1_score: 0.7399\n",
      "Epoch 33/1000\n",
      "101/101 [==============================] - 35s 334ms/step - loss: 0.0287 - f1_score: 0.9681 - val_loss: 0.9053 - val_f1_score: 0.7699\n",
      "Epoch 34/1000\n",
      "101/101 [==============================] - 38s 347ms/step - loss: 0.1148 - f1_score: 0.9432 - val_loss: 1.0459 - val_f1_score: 0.7340\n",
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    base_model.trainable = True\n",
    "    model.compile(optimizer=keras.optimizers.Adam(2e-4), loss='categorical_crossentropy', metrics=[F1Score(num_classes=n_classes, average='macro')])\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=1000, callbacks=get_callbacks(patience=10, plot_path=join(PATH.result, 'proposed3', 'fine_tuning')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ec114",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c990309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  label\n",
       "index                  \n",
       "0       tile-glue_strip\n",
       "1             grid-good\n",
       "2       transistor-good\n",
       "3      tile-gray_stroke\n",
       "4             tile-good\n",
       "...                 ...\n",
       "2149   tile-gray_stroke\n",
       "2150         screw-good\n",
       "2151          grid-good\n",
       "2152         cable-good\n",
       "2153        zipper-good\n",
       "\n",
       "[2154 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file_path = join(PATH.output, 'proposed3_fine_tuning.csv')\n",
    "\n",
    "pred_test = model.predict(test_ds)\n",
    "submission = pd.read_csv(join(PATH.input, 'sample_submission.csv'), index_col=0)\n",
    "submission['label'] = y_enc.inverse_transform(pred_test)\n",
    "submission.to_csv(submission_file_path)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3912a8",
   "metadata": {},
   "source": [
    "# 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb4c06fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': True, 'detail': 'Success'}\n"
     ]
    }
   ],
   "source": [
    "from dacon_submit_api.dacon_submit_api import post_submission_file\n",
    "\n",
    "result = post_submission_file(\n",
    "    submission_file_path,\n",
    "    '137ff236e305f302819b930b3b5b72e948603f23c5249a516c32b536d5187a03', \n",
    "    '235894', \n",
    "    '어스름한 금요일 밤에', \n",
    "    'proposed3_fine_tuning'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
