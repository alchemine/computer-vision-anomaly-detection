{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2743d5c",
   "metadata": {},
   "source": [
    "# 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b63b6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    }
   ],
   "source": [
    "from analysis_tools.common import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import sklearn\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "sklearn.random.seed(RANDOM_STATE)\n",
    "\n",
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083ee50",
   "metadata": {},
   "source": [
    "# 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6eba851",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  7.7s\n",
      "[########################################] | 100% Completed |  3.6s\n",
      "- Number of train full data: 4277\n",
      "- Number of test data: 2154\n"
     ]
    }
   ],
   "source": [
    "train_full_data_meta = pd.read_csv(join(PATH.input, 'train_df.csv'), index_col=0)\n",
    "test_data_meta       = pd.read_csv(join(PATH.input, 'test_df.csv'), index_col=0)\n",
    "\n",
    "with ProgressBar():\n",
    "    X_train_full = compute(*[delayed(cv2.imread)(path) for path in ls_file(PATH.train)])\n",
    "    X_test       = compute(*[delayed(cv2.imread)(path) for path in ls_file(PATH.test)])\n",
    "y_train_full = train_full_data_meta[['label']]\n",
    "    \n",
    "print(\"- Number of train full data:\", len(X_train_full))\n",
    "print(\"- Number of test data:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508182a",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e372118e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2.3s\n",
      "[########################################] | 100% Completed |  0.9s\n",
      "- Number of classes: 88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "IMG_SIZE    = 512\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "with ProgressBar():\n",
    "    X_train_full = np.array(compute(*[delayed(cv2.resize)(X, [IMG_SIZE, IMG_SIZE]) for X in X_train_full]))\n",
    "    X_test       = np.array(compute(*[delayed(cv2.resize)(X, [IMG_SIZE, IMG_SIZE]) for X in X_test]))\n",
    "y_enc = OneHotEncoder(sparse=False, dtype=bool)\n",
    "y_train_full = y_enc.fit_transform(y_train_full)\n",
    "n_classes = len(y_enc.categories_[0])\n",
    "print(\"- Number of classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1d1139",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aug_model = keras.models.Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "def preprocess(ds, training, batch_size, augment=True):\n",
    "    ds = ds.cache().batch(batch_size)\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=1000).prefetch(tf.data.AUTOTUNE)\n",
    "        if augment:\n",
    "            ds = ds.map(lambda X, y, sw: (aug_model(X), y, sw), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# fig, axes = plt.subplots(5, 15, figsize=(30, 10))\n",
    "# for row, ax_cols in enumerate(axes):\n",
    "#     for ax in ax_cols:\n",
    "#         ax.imshow(aug_model(X_train_full[row]))\n",
    "#         ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20862d",
   "metadata": {},
   "source": [
    "## 3.1 Fix pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aef44e53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train.shape: (3207, 512, 512, 3) (3207, 88)\n",
      "- val.shape: (1070, 512, 512, 3) (1070, 88)\n",
      "- test.shape: (2154, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, stratify=y_train_full)\n",
    "sample_weight_train = compute_sample_weight(class_weight='balanced', y=y_train.argmax(1))\n",
    "sample_weight_val   = compute_sample_weight(class_weight='balanced', y=y_val.argmax(1))\n",
    "\n",
    "train_ds = preprocess(tf.data.Dataset.from_tensor_slices((X_train, y_train, sample_weight_train)), True, BATCH_SIZE)\n",
    "val_ds   = preprocess(tf.data.Dataset.from_tensor_slices((X_val, y_val, sample_weight_val)), False, BATCH_SIZE)\n",
    "test_ds  = preprocess(tf.data.Dataset.from_tensor_slices(X_test), False, BATCH_SIZE)\n",
    "\n",
    "print(\"- train.shape:\", X_train.shape, y_train.shape)\n",
    "print(\"- val.shape:\", X_val.shape, y_val.shape)\n",
    "print(\"- test.shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e1e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.metrics import F1Score\n",
    "\n",
    "def build_model(n_classes, strategy):\n",
    "    with strategy.scope():\n",
    "        base_model = keras.applications.EfficientNetB0(include_top=False, input_shape=input_shape)\n",
    "        base_model.trainable = False\n",
    "\n",
    "        inputs  = keras.Input(input_shape)\n",
    "        hidden  = base_model(inputs, training=False)\n",
    "        hidden  = keras.layers.GlobalAveragePooling2D()(hidden)\n",
    "        outputs = keras.layers.Dense(n_classes, activation='softmax')(hidden)\n",
    "        model   = keras.Model(inputs, outputs)\n",
    "        \n",
    "        model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=[F1Score(num_classes=n_classes, average='macro')])\n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5171581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "learning rate:  6.666666666666667e-05\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  6/101 [>.............................] - ETA: 1:02 - loss: 4.1149 - f1_score: 0.0013    WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0489s vs `on_train_batch_begin` time: 0.3765s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0489s vs `on_train_batch_end` time: 0.1286s). Check your callbacks.\n",
      "101/101 [==============================] - 43s 190ms/step - loss: 4.3492 - f1_score: 0.0400 - val_loss: 4.1480 - val_f1_score: 0.0767\n",
      "Epoch 2/200\n",
      "learning rate:  0.00013333333333333334\n",
      "101/101 [==============================] - 13s 98ms/step - loss: 3.8217 - f1_score: 0.1506 - val_loss: 3.4854 - val_f1_score: 0.1563\n",
      "Epoch 3/200\n",
      "learning rate:  0.0002\n",
      "101/101 [==============================] - 13s 102ms/step - loss: 3.1721 - f1_score: 0.1703 - val_loss: 2.8498 - val_f1_score: 0.1752\n",
      "Epoch 4/200\n",
      "learning rate:  0.00026666666666666668\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 2.6185 - f1_score: 0.1845 - val_loss: 2.3609 - val_f1_score: 0.2169\n",
      "Epoch 5/200\n",
      "learning rate:  0.00033333333333333332\n",
      "101/101 [==============================] - 14s 99ms/step - loss: 2.2042 - f1_score: 0.2622 - val_loss: 2.0485 - val_f1_score: 0.2486\n",
      "Epoch 6/200\n",
      "learning rate:  0.0004\n",
      "101/101 [==============================] - 13s 98ms/step - loss: 1.9507 - f1_score: 0.2940 - val_loss: 1.8514 - val_f1_score: 0.2926\n",
      "Epoch 7/200\n",
      "learning rate:  0.00046666666666666666\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 1.7651 - f1_score: 0.3250 - val_loss: 1.7319 - val_f1_score: 0.3004\n",
      "Epoch 8/200\n",
      "learning rate:  0.00053333333333333336\n",
      "101/101 [==============================] - 14s 111ms/step - loss: 1.6549 - f1_score: 0.3355 - val_loss: 1.6365 - val_f1_score: 0.3362\n",
      "Epoch 9/200\n",
      "learning rate:  0.0006\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 1.5628 - f1_score: 0.3703 - val_loss: 1.5670 - val_f1_score: 0.3873\n",
      "Epoch 10/200\n",
      "learning rate:  0.00066666666666666664\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 1.5062 - f1_score: 0.3712 - val_loss: 1.5177 - val_f1_score: 0.3234\n",
      "Epoch 11/200\n",
      "learning rate:  0.00073333333333333334\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 1.3971 - f1_score: 0.4069 - val_loss: 1.4334 - val_f1_score: 0.4404\n",
      "Epoch 12/200\n",
      "learning rate:  0.0008\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 1.3332 - f1_score: 0.4203 - val_loss: 1.4448 - val_f1_score: 0.3824\n",
      "Epoch 13/200\n",
      "learning rate:  0.00086666666666666674\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 1.2843 - f1_score: 0.4330 - val_loss: 1.3711 - val_f1_score: 0.3692\n",
      "Epoch 14/200\n",
      "learning rate:  0.00093333333333333332\n",
      "101/101 [==============================] - 13s 98ms/step - loss: 1.2275 - f1_score: 0.4537 - val_loss: 1.3788 - val_f1_score: 0.3584\n",
      "Epoch 15/200\n",
      "learning rate:  0.001\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 1.1568 - f1_score: 0.4819 - val_loss: 1.3835 - val_f1_score: 0.3967\n",
      "Epoch 16/200\n",
      "learning rate:  0.0010666666666666667\n",
      "101/101 [==============================] - 13s 98ms/step - loss: 1.1409 - f1_score: 0.4829 - val_loss: 1.3008 - val_f1_score: 0.4009\n",
      "Epoch 17/200\n",
      "learning rate:  0.0011333333333333334\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 1.0947 - f1_score: 0.4983 - val_loss: 1.2543 - val_f1_score: 0.4159\n",
      "Epoch 18/200\n",
      "learning rate:  0.0012\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 1.0454 - f1_score: 0.5340 - val_loss: 1.2573 - val_f1_score: 0.4372\n",
      "Epoch 19/200\n",
      "learning rate:  0.0012666666666666666\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 1.0020 - f1_score: 0.5198 - val_loss: 1.2681 - val_f1_score: 0.4278\n",
      "Epoch 20/200\n",
      "learning rate:  0.0013333333333333333\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.9236 - f1_score: 0.5470 - val_loss: 1.2180 - val_f1_score: 0.4272\n",
      "Epoch 21/200\n",
      "learning rate:  0.0014\n",
      "101/101 [==============================] - 13s 108ms/step - loss: 0.9163 - f1_score: 0.5428 - val_loss: 1.2161 - val_f1_score: 0.4669\n",
      "Epoch 22/200\n",
      "learning rate:  0.0014666666666666667\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.9173 - f1_score: 0.5604 - val_loss: 1.2121 - val_f1_score: 0.4645\n",
      "Epoch 23/200\n",
      "learning rate:  0.0015333333333333334\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.8929 - f1_score: 0.5646 - val_loss: 1.1643 - val_f1_score: 0.4881\n",
      "Epoch 24/200\n",
      "learning rate:  0.0016\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.8416 - f1_score: 0.6000 - val_loss: 1.2012 - val_f1_score: 0.4449\n",
      "Epoch 25/200\n",
      "learning rate:  0.0016666666666666668\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.8469 - f1_score: 0.5759 - val_loss: 1.1952 - val_f1_score: 0.4338\n",
      "Epoch 26/200\n",
      "learning rate:  0.0017333333333333335\n",
      "101/101 [==============================] - 12s 97ms/step - loss: 0.8234 - f1_score: 0.5739 - val_loss: 1.1540 - val_f1_score: 0.4471\n",
      "Epoch 27/200\n",
      "learning rate:  0.0018000000000000002\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.7839 - f1_score: 0.5875 - val_loss: 1.1631 - val_f1_score: 0.4718\n",
      "Epoch 28/200\n",
      "learning rate:  0.0018666666666666666\n",
      "101/101 [==============================] - 12s 108ms/step - loss: 0.7675 - f1_score: 0.5961 - val_loss: 1.1195 - val_f1_score: 0.4770\n",
      "Epoch 29/200\n",
      "learning rate:  0.0019333333333333333\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.7659 - f1_score: 0.6090 - val_loss: 1.1707 - val_f1_score: 0.4600\n",
      "Epoch 30/200\n",
      "learning rate:  0.002\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.7087 - f1_score: 0.6238 - val_loss: 1.1598 - val_f1_score: 0.5070\n",
      "Epoch 31/200\n",
      "learning rate:  0.00199411763\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.6965 - f1_score: 0.6318 - val_loss: 1.0786 - val_f1_score: 0.4910\n",
      "Epoch 32/200\n",
      "learning rate:  0.0019882354\n",
      "101/101 [==============================] - 15s 110ms/step - loss: 0.6855 - f1_score: 0.6564 - val_loss: 1.1319 - val_f1_score: 0.5216\n",
      "Epoch 33/200\n",
      "learning rate:  0.00198235316\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.6617 - f1_score: 0.6543 - val_loss: 1.1837 - val_f1_score: 0.4870\n",
      "Epoch 34/200\n",
      "learning rate:  0.0019764707\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.6496 - f1_score: 0.6592 - val_loss: 1.1211 - val_f1_score: 0.5009\n",
      "Epoch 35/200\n",
      "learning rate:  0.00197058823\n",
      "101/101 [==============================] - 13s 98ms/step - loss: 0.5808 - f1_score: 0.6915 - val_loss: 1.1940 - val_f1_score: 0.4775\n",
      "Epoch 36/200\n",
      "learning rate:  0.001964706\n",
      "101/101 [==============================] - 13s 97ms/step - loss: 0.6382 - f1_score: 0.6745 - val_loss: 1.1234 - val_f1_score: 0.5229\n",
      "Epoch 37/200\n",
      "learning rate:  0.00195882353\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.5719 - f1_score: 0.6891 - val_loss: 1.0920 - val_f1_score: 0.5109\n",
      "Epoch 38/200\n",
      "learning rate:  0.0019529413\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.5369 - f1_score: 0.6971 - val_loss: 1.0860 - val_f1_score: 0.5348\n",
      "Epoch 39/200\n",
      "learning rate:  0.00194705883\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.5676 - f1_score: 0.6955 - val_loss: 1.1034 - val_f1_score: 0.5382\n",
      "Epoch 40/200\n",
      "learning rate:  0.0019411766\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.5513 - f1_score: 0.6999 - val_loss: 1.1024 - val_f1_score: 0.5424\n",
      "Epoch 41/200\n",
      "learning rate:  0.00193529413\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.5429 - f1_score: 0.6939 - val_loss: 1.1072 - val_f1_score: 0.5097\n",
      "Epoch 42/200\n",
      "learning rate:  0.00192941178\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.5319 - f1_score: 0.6985 - val_loss: 1.0680 - val_f1_score: 0.5574\n",
      "Epoch 43/200\n",
      "learning rate:  0.00192352943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 13s 98ms/step - loss: 0.5182 - f1_score: 0.7102 - val_loss: 1.0383 - val_f1_score: 0.5366\n",
      "Epoch 44/200\n",
      "learning rate:  0.0019176472\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.4998 - f1_score: 0.7117 - val_loss: 1.0594 - val_f1_score: 0.5291\n",
      "Epoch 45/200\n",
      "learning rate:  0.00191176473\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.5042 - f1_score: 0.7230 - val_loss: 1.1501 - val_f1_score: 0.5019\n",
      "Epoch 46/200\n",
      "learning rate:  0.00190588238\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.4705 - f1_score: 0.7378 - val_loss: 1.1389 - val_f1_score: 0.5546\n",
      "Epoch 47/200\n",
      "learning rate:  0.0019\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.4988 - f1_score: 0.7063 - val_loss: 1.0944 - val_f1_score: 0.5029\n",
      "Epoch 48/200\n",
      "learning rate:  0.0018941178\n",
      "101/101 [==============================] - 13s 101ms/step - loss: 0.4705 - f1_score: 0.7164 - val_loss: 1.1095 - val_f1_score: 0.5702\n",
      "Epoch 49/200\n",
      "learning rate:  0.00188823533\n",
      "101/101 [==============================] - 13s 97ms/step - loss: 0.4867 - f1_score: 0.7220 - val_loss: 1.1094 - val_f1_score: 0.5107\n",
      "Epoch 50/200\n",
      "learning rate:  0.0018823531\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.4737 - f1_score: 0.7428 - val_loss: 1.0707 - val_f1_score: 0.5585\n",
      "Epoch 51/200\n",
      "learning rate:  0.00187647063\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.4330 - f1_score: 0.7548 - val_loss: 1.0746 - val_f1_score: 0.5708\n",
      "Epoch 52/200\n",
      "learning rate:  0.0018705884\n",
      "101/101 [==============================] - 13s 101ms/step - loss: 0.4429 - f1_score: 0.7355 - val_loss: 1.1819 - val_f1_score: 0.5311\n",
      "Epoch 53/200\n",
      "learning rate:  0.00186470593\n",
      "101/101 [==============================] - 12s 101ms/step - loss: 0.4250 - f1_score: 0.7428 - val_loss: 1.0954 - val_f1_score: 0.5276\n",
      "Epoch 54/200\n",
      "learning rate:  0.00185882358\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.4309 - f1_score: 0.7563 - val_loss: 1.0327 - val_f1_score: 0.5540\n",
      "Epoch 55/200\n",
      "learning rate:  0.00185294123\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.4193 - f1_score: 0.7373 - val_loss: 1.0960 - val_f1_score: 0.5203\n",
      "Epoch 56/200\n",
      "learning rate:  0.001847059\n",
      "101/101 [==============================] - 12s 97ms/step - loss: 0.3949 - f1_score: 0.7614 - val_loss: 1.0215 - val_f1_score: 0.5496\n",
      "Epoch 57/200\n",
      "learning rate:  0.00184117653\n",
      "101/101 [==============================] - 13s 98ms/step - loss: 0.4005 - f1_score: 0.7536 - val_loss: 1.0749 - val_f1_score: 0.5563\n",
      "Epoch 58/200\n",
      "learning rate:  0.00183529407\n",
      "101/101 [==============================] - 12s 101ms/step - loss: 0.4171 - f1_score: 0.7574 - val_loss: 1.1755 - val_f1_score: 0.5542\n",
      "Epoch 59/200\n",
      "learning rate:  0.00182941183\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.3906 - f1_score: 0.7644 - val_loss: 1.0575 - val_f1_score: 0.5578\n",
      "Epoch 60/200\n",
      "learning rate:  0.00182352948\n",
      "101/101 [==============================] - 14s 108ms/step - loss: 0.3842 - f1_score: 0.7704 - val_loss: 1.0932 - val_f1_score: 0.5488\n",
      "Epoch 61/200\n",
      "learning rate:  0.00181764713\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.3789 - f1_score: 0.7682 - val_loss: 1.0961 - val_f1_score: 0.5695\n",
      "Epoch 62/200\n",
      "learning rate:  0.00181176479\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.3670 - f1_score: 0.7842 - val_loss: 1.0696 - val_f1_score: 0.5982\n",
      "Epoch 63/200\n",
      "learning rate:  0.00180588244\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.3930 - f1_score: 0.7712 - val_loss: 1.0707 - val_f1_score: 0.5509\n",
      "Epoch 64/200\n",
      "learning rate:  0.00180000009\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.3714 - f1_score: 0.7801 - val_loss: 1.1665 - val_f1_score: 0.5137\n",
      "Epoch 65/200\n",
      "learning rate:  0.00179411774\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.3702 - f1_score: 0.7803 - val_loss: 1.0595 - val_f1_score: 0.5601\n",
      "Epoch 66/200\n",
      "learning rate:  0.00178823539\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.3756 - f1_score: 0.7623 - val_loss: 1.1874 - val_f1_score: 0.5180\n",
      "Epoch 67/200\n",
      "learning rate:  0.00178235304\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.3519 - f1_score: 0.7910 - val_loss: 1.2050 - val_f1_score: 0.5211\n",
      "Epoch 68/200\n",
      "learning rate:  0.00177647057\n",
      "101/101 [==============================] - 12s 96ms/step - loss: 0.3585 - f1_score: 0.7869 - val_loss: 1.1831 - val_f1_score: 0.5266\n",
      "Epoch 69/200\n",
      "learning rate:  0.00177058834\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.3713 - f1_score: 0.7633 - val_loss: 1.0131 - val_f1_score: 0.5862\n",
      "Epoch 70/200\n",
      "learning rate:  0.00176470587\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.3302 - f1_score: 0.7940 - val_loss: 1.1302 - val_f1_score: 0.5597\n",
      "Epoch 71/200\n",
      "learning rate:  0.00175882352\n",
      "101/101 [==============================] - 14s 100ms/step - loss: 0.3812 - f1_score: 0.7649 - val_loss: 1.1901 - val_f1_score: 0.5386\n",
      "Epoch 72/200\n",
      "learning rate:  0.00175294129\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.3348 - f1_score: 0.7930 - val_loss: 1.1417 - val_f1_score: 0.5692\n",
      "Epoch 73/200\n",
      "learning rate:  0.00174705882\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.2996 - f1_score: 0.8025 - val_loss: 1.1565 - val_f1_score: 0.5784\n",
      "Epoch 74/200\n",
      "learning rate:  0.00174117659\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.3022 - f1_score: 0.8067 - val_loss: 1.0816 - val_f1_score: 0.5768\n",
      "Epoch 75/200\n",
      "learning rate:  0.00173529424\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.3247 - f1_score: 0.8014 - val_loss: 1.1785 - val_f1_score: 0.5649\n",
      "Epoch 76/200\n",
      "learning rate:  0.00172941177\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.3425 - f1_score: 0.7904 - val_loss: 1.1247 - val_f1_score: 0.5638\n",
      "Epoch 77/200\n",
      "learning rate:  0.00172352954\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.3121 - f1_score: 0.8018 - val_loss: 1.1760 - val_f1_score: 0.5282\n",
      "Epoch 78/200\n",
      "learning rate:  0.00171764707\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.3039 - f1_score: 0.7958 - val_loss: 1.1526 - val_f1_score: 0.5596\n",
      "Epoch 79/200\n",
      "learning rate:  0.00171176484\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.3207 - f1_score: 0.7774 - val_loss: 1.1787 - val_f1_score: 0.5599\n",
      "Epoch 80/200\n",
      "learning rate:  0.00170588237\n",
      "101/101 [==============================] - 12s 97ms/step - loss: 0.3339 - f1_score: 0.7992 - val_loss: 1.0970 - val_f1_score: 0.5801\n",
      "Epoch 81/200\n",
      "learning rate:  0.0017\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.3192 - f1_score: 0.7855 - val_loss: 1.1834 - val_f1_score: 0.5516\n",
      "Epoch 82/200\n",
      "learning rate:  0.00169411767\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.3131 - f1_score: 0.7928 - val_loss: 1.1955 - val_f1_score: 0.5414\n",
      "Epoch 83/200\n",
      "learning rate:  0.00168823544\n",
      "101/101 [==============================] - 13s 109ms/step - loss: 0.3078 - f1_score: 0.8094 - val_loss: 1.1417 - val_f1_score: 0.5601\n",
      "Epoch 84/200\n",
      "learning rate:  0.00168235297\n",
      "101/101 [==============================] - 13s 101ms/step - loss: 0.2634 - f1_score: 0.8174 - val_loss: 1.2049 - val_f1_score: 0.5703\n",
      "Epoch 85/200\n",
      "learning rate:  0.00167647074\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.2711 - f1_score: 0.8252 - val_loss: 1.2238 - val_f1_score: 0.5762\n",
      "Epoch 86/200\n",
      "learning rate:  0.00167058827\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.2678 - f1_score: 0.8285 - val_loss: 1.1577 - val_f1_score: 0.5800\n",
      "Epoch 87/200\n",
      "learning rate:  0.00166470592\n",
      "101/101 [==============================] - 13s 98ms/step - loss: 0.2991 - f1_score: 0.8179 - val_loss: 1.1763 - val_f1_score: 0.5813\n",
      "Epoch 88/200\n",
      "learning rate:  0.00165882357\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.2711 - f1_score: 0.8229 - val_loss: 1.1771 - val_f1_score: 0.5743\n",
      "Epoch 89/200\n",
      "learning rate:  0.00165294111\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.2661 - f1_score: 0.8266 - val_loss: 1.2165 - val_f1_score: 0.5199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "learning rate:  0.00164705887\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.2641 - f1_score: 0.8130 - val_loss: 1.2227 - val_f1_score: 0.5567\n",
      "Epoch 91/200\n",
      "learning rate:  0.00164117652\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.2736 - f1_score: 0.8193 - val_loss: 1.1782 - val_f1_score: 0.5496\n",
      "Epoch 92/200\n",
      "learning rate:  0.00163529417\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.2585 - f1_score: 0.8258 - val_loss: 1.2748 - val_f1_score: 0.5251\n",
      "Epoch 93/200\n",
      "learning rate:  0.00162941182\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.2637 - f1_score: 0.8233 - val_loss: 1.3168 - val_f1_score: 0.5368\n",
      "Epoch 94/200\n",
      "learning rate:  0.00162352948\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.2680 - f1_score: 0.8245 - val_loss: 1.1637 - val_f1_score: 0.5835\n",
      "Epoch 95/200\n",
      "learning rate:  0.00161764713\n",
      "101/101 [==============================] - 14s 109ms/step - loss: 0.2785 - f1_score: 0.8109 - val_loss: 1.2128 - val_f1_score: 0.5771\n",
      "Epoch 96/200\n",
      "learning rate:  0.00161176478\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.2576 - f1_score: 0.8352 - val_loss: 1.2389 - val_f1_score: 0.5723\n",
      "Epoch 97/200\n",
      "learning rate:  0.00160588243\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.2769 - f1_score: 0.8293 - val_loss: 1.3695 - val_f1_score: 0.5846\n",
      "Epoch 98/200\n",
      "learning rate:  0.00160000008\n",
      "101/101 [==============================] - 13s 98ms/step - loss: 0.2642 - f1_score: 0.8288 - val_loss: 1.2208 - val_f1_score: 0.5829\n",
      "Epoch 99/200\n",
      "learning rate:  0.00159411773\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.2592 - f1_score: 0.8267 - val_loss: 1.2434 - val_f1_score: 0.5817\n",
      "Epoch 100/200\n",
      "learning rate:  0.00158823538\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.2487 - f1_score: 0.8355 - val_loss: 1.2771 - val_f1_score: 0.5622\n",
      "Epoch 101/200\n",
      "learning rate:  0.00158235303\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.2787 - f1_score: 0.8213 - val_loss: 1.2422 - val_f1_score: 0.5637\n",
      "Epoch 102/200\n",
      "learning rate:  0.00157647068\n",
      "101/101 [==============================] - 14s 110ms/step - loss: 0.2299 - f1_score: 0.8430 - val_loss: 1.1910 - val_f1_score: 0.5425\n",
      "Epoch 103/200\n",
      "learning rate:  0.00157058833\n",
      "101/101 [==============================] - 12s 97ms/step - loss: 0.2543 - f1_score: 0.8226 - val_loss: 1.2931 - val_f1_score: 0.5429\n",
      "Epoch 104/200\n",
      "learning rate:  0.00156470598\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.2360 - f1_score: 0.8407 - val_loss: 1.2618 - val_f1_score: 0.5259\n",
      "Epoch 105/200\n",
      "learning rate:  0.00155882351\n",
      "101/101 [==============================] - 12s 97ms/step - loss: 0.2246 - f1_score: 0.8378 - val_loss: 1.2872 - val_f1_score: 0.5617\n",
      "Epoch 106/200\n",
      "learning rate:  0.00155294128\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.2300 - f1_score: 0.8355 - val_loss: 1.2344 - val_f1_score: 0.6090\n",
      "Epoch 107/200\n",
      "learning rate:  0.00154705881\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.2444 - f1_score: 0.8303 - val_loss: 1.2379 - val_f1_score: 0.5837\n",
      "Epoch 108/200\n",
      "learning rate:  0.00154117658\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.2387 - f1_score: 0.8448 - val_loss: 1.2204 - val_f1_score: 0.5485\n",
      "Epoch 109/200\n",
      "learning rate:  0.00153529411\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.2526 - f1_score: 0.8263 - val_loss: 1.2504 - val_f1_score: 0.5392\n",
      "Epoch 110/200\n",
      "learning rate:  0.00152941188\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.2561 - f1_score: 0.8358 - val_loss: 1.2351 - val_f1_score: 0.5938\n",
      "Epoch 111/200\n",
      "learning rate:  0.00152352941\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.2275 - f1_score: 0.8342 - val_loss: 1.1533 - val_f1_score: 0.5510\n",
      "Epoch 112/200\n",
      "learning rate:  0.00151764706\n",
      "101/101 [==============================] - 13s 100ms/step - loss: 0.2209 - f1_score: 0.8354 - val_loss: 1.0982 - val_f1_score: 0.6092\n",
      "Epoch 113/200\n",
      "learning rate:  0.00151176471\n",
      "101/101 [==============================] - 12s 98ms/step - loss: 0.2192 - f1_score: 0.8530 - val_loss: 1.2136 - val_f1_score: 0.5816\n",
      "Epoch 114/200\n",
      "learning rate:  0.00150588248\n",
      "101/101 [==============================] - 12s 100ms/step - loss: 0.2051 - f1_score: 0.8393 - val_loss: 1.2625 - val_f1_score: 0.5747\n",
      "Epoch 115/200\n",
      "learning rate:  0.0015\n",
      "101/101 [==============================] - 12s 99ms/step - loss: 0.2177 - f1_score: 0.8489 - val_loss: 1.2181 - val_f1_score: 0.5831\n",
      "Epoch 116/200\n",
      "learning rate:  0.00149411766\n",
      "101/101 [==============================] - 13s 101ms/step - loss: 0.2220 - f1_score: 0.8425 - val_loss: 1.2536 - val_f1_score: 0.5700\n",
      "Epoch 117/200\n",
      "learning rate:  0.00148823531\n",
      "101/101 [==============================] - 12s 97ms/step - loss: 0.2207 - f1_score: 0.8585 - val_loss: 1.3137 - val_f1_score: 0.5464\n",
      "Epoch 118/200\n",
      "learning rate:  0.00148235296\n",
      "101/101 [==============================] - 15s 112ms/step - loss: 0.2296 - f1_score: 0.8406 - val_loss: 1.2684 - val_f1_score: 0.5681\n",
      "Epoch 119/200\n",
      "learning rate:  0.00147647061\n",
      "101/101 [==============================] - 13s 99ms/step - loss: 0.2201 - f1_score: 0.8470 - val_loss: 1.1817 - val_f1_score: 0.5909\n",
      "Epoch 00119: early stopping\n"
     ]
    }
   ],
   "source": [
    "from analysis_tools.modeling import *\n",
    "\n",
    "model, base_model = build_model(n_classes, strategy)\n",
    "epochs = 200\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=get_callbacks(patience=50, plot_path=join(PATH.result, 'proposed3', 'fix_pretrained_model_nadam_lr_scheduler'), init_lr=2e-3, epochs=epochs, warmup_epoch=30, min_lr=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4016a27",
   "metadata": {},
   "source": [
    "## 3.2 Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a6cf4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "learning rate:  6.6666666666666666e-06\n",
      "INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  6/101 [>.............................] - ETA: 3:00 - loss: 0.4174 - f1_score: 0.4297WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.3550s vs `on_train_batch_begin` time: 0.3609s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3550s vs `on_train_batch_end` time: 0.9244s). Check your callbacks.\n",
      "101/101 [==============================] - 114s 499ms/step - loss: 0.1909 - f1_score: 0.8554 - val_loss: 1.2678 - val_f1_score: 0.5980\n",
      "Epoch 2/200\n",
      "learning rate:  1.3333333333333333e-05\n",
      "101/101 [==============================] - 39s 362ms/step - loss: 0.2275 - f1_score: 0.8356 - val_loss: 1.2652 - val_f1_score: 0.5674\n",
      "Epoch 3/200\n",
      "learning rate:  2e-05\n",
      "101/101 [==============================] - 39s 363ms/step - loss: 0.2527 - f1_score: 0.8173 - val_loss: 1.2961 - val_f1_score: 0.5992\n",
      "Epoch 4/200\n",
      "learning rate:  2.6666666666666667e-05\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.3601 - f1_score: 0.7790 - val_loss: 1.3069 - val_f1_score: 0.5455\n",
      "Epoch 5/200\n",
      "learning rate:  3.3333333333333335e-05\n",
      "101/101 [==============================] - 39s 366ms/step - loss: 0.3927 - f1_score: 0.7591 - val_loss: 1.3235 - val_f1_score: 0.5776\n",
      "Epoch 6/200\n",
      "learning rate:  4e-05\n",
      "101/101 [==============================] - 39s 363ms/step - loss: 0.3426 - f1_score: 0.7819 - val_loss: 1.3847 - val_f1_score: 0.5574\n",
      "Epoch 7/200\n",
      "learning rate:  4.6666666666666672e-05\n",
      "101/101 [==============================] - 38s 361ms/step - loss: 0.3783 - f1_score: 0.7574 - val_loss: 1.4267 - val_f1_score: 0.5540\n",
      "Epoch 8/200\n",
      "learning rate:  5.3333333333333333e-05\n",
      "101/101 [==============================] - 39s 361ms/step - loss: 0.3227 - f1_score: 0.7942 - val_loss: 1.2752 - val_f1_score: 0.5908\n",
      "Epoch 9/200\n",
      "learning rate:  6e-05\n",
      "101/101 [==============================] - 39s 365ms/step - loss: 0.3623 - f1_score: 0.7772 - val_loss: 1.2535 - val_f1_score: 0.6308\n",
      "Epoch 10/200\n",
      "learning rate:  6.666666666666667e-05\n",
      "101/101 [==============================] - 40s 361ms/step - loss: 0.3670 - f1_score: 0.7687 - val_loss: 1.3095 - val_f1_score: 0.5620\n",
      "Epoch 11/200\n",
      "learning rate:  7.3333333333333331e-05\n",
      "101/101 [==============================] - 40s 361ms/step - loss: 0.3745 - f1_score: 0.7839 - val_loss: 1.2337 - val_f1_score: 0.5888\n",
      "Epoch 12/200\n",
      "learning rate:  8e-05\n",
      "101/101 [==============================] - 38s 364ms/step - loss: 0.3259 - f1_score: 0.7793 - val_loss: 1.1427 - val_f1_score: 0.6259\n",
      "Epoch 13/200\n",
      "learning rate:  8.6666666666666668e-05\n",
      "101/101 [==============================] - 39s 369ms/step - loss: 0.3213 - f1_score: 0.7925 - val_loss: 1.2477 - val_f1_score: 0.6121\n",
      "Epoch 14/200\n",
      "learning rate:  9.3333333333333343e-05\n",
      "101/101 [==============================] - 39s 362ms/step - loss: 0.2826 - f1_score: 0.8083 - val_loss: 1.1911 - val_f1_score: 0.6190\n",
      "Epoch 15/200\n",
      "learning rate:  0.0001\n",
      "101/101 [==============================] - 38s 361ms/step - loss: 0.2524 - f1_score: 0.8295 - val_loss: 1.3787 - val_f1_score: 0.5842\n",
      "Epoch 16/200\n",
      "learning rate:  0.00010666666666666667\n",
      "101/101 [==============================] - 40s 374ms/step - loss: 0.4575 - f1_score: 0.7522 - val_loss: 1.0780 - val_f1_score: 0.6408\n",
      "Epoch 17/200\n",
      "learning rate:  0.00011333333333333334\n",
      "101/101 [==============================] - 40s 360ms/step - loss: 0.2436 - f1_score: 0.8111 - val_loss: 1.0933 - val_f1_score: 0.6942\n",
      "Epoch 18/200\n",
      "learning rate:  0.00012\n",
      "101/101 [==============================] - 39s 362ms/step - loss: 0.3579 - f1_score: 0.7896 - val_loss: 1.2811 - val_f1_score: 0.6225\n",
      "Epoch 19/200\n",
      "learning rate:  0.00012666666666666666\n",
      "101/101 [==============================] - 40s 366ms/step - loss: 0.4407 - f1_score: 0.7790 - val_loss: 1.1046 - val_f1_score: 0.6663\n",
      "Epoch 20/200\n",
      "learning rate:  0.00013333333333333334\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 0.3822 - f1_score: 0.7608 - val_loss: 1.5285 - val_f1_score: 0.5983\n",
      "Epoch 21/200\n",
      "learning rate:  0.00014\n",
      "101/101 [==============================] - 40s 362ms/step - loss: 0.2576 - f1_score: 0.8328 - val_loss: 1.3164 - val_f1_score: 0.6566\n",
      "Epoch 22/200\n",
      "learning rate:  0.00014666666666666666\n",
      "101/101 [==============================] - 40s 361ms/step - loss: 0.1832 - f1_score: 0.8554 - val_loss: 1.2713 - val_f1_score: 0.6913\n",
      "Epoch 23/200\n",
      "learning rate:  0.00015333333333333334\n",
      "101/101 [==============================] - 38s 361ms/step - loss: 0.1697 - f1_score: 0.8777 - val_loss: 1.1318 - val_f1_score: 0.6789\n",
      "Epoch 24/200\n",
      "learning rate:  0.00016\n",
      "101/101 [==============================] - 39s 362ms/step - loss: 0.1895 - f1_score: 0.8863 - val_loss: 1.2953 - val_f1_score: 0.7283\n",
      "Epoch 25/200\n",
      "learning rate:  0.00016666666666666669\n",
      "101/101 [==============================] - 40s 362ms/step - loss: 0.1678 - f1_score: 0.8623 - val_loss: 1.1410 - val_f1_score: 0.7179\n",
      "Epoch 26/200\n",
      "learning rate:  0.00017333333333333334\n",
      "101/101 [==============================] - 39s 358ms/step - loss: 0.0949 - f1_score: 0.9053 - val_loss: 1.2700 - val_f1_score: 0.7072\n",
      "Epoch 27/200\n",
      "learning rate:  0.00018\n",
      "101/101 [==============================] - 39s 361ms/step - loss: 0.2903 - f1_score: 0.8423 - val_loss: 1.5097 - val_f1_score: 0.6352\n",
      "Epoch 28/200\n",
      "learning rate:  0.00018666666666666669\n",
      "101/101 [==============================] - 39s 361ms/step - loss: 0.1743 - f1_score: 0.8674 - val_loss: 1.4146 - val_f1_score: 0.6717\n",
      "Epoch 29/200\n",
      "learning rate:  0.00019333333333333333\n",
      "101/101 [==============================] - 40s 364ms/step - loss: 0.2586 - f1_score: 0.8791 - val_loss: 1.3249 - val_f1_score: 0.6858\n",
      "Epoch 30/200\n",
      "learning rate:  0.0002\n",
      "101/101 [==============================] - 38s 361ms/step - loss: 0.3402 - f1_score: 0.8209 - val_loss: 1.1390 - val_f1_score: 0.6939\n",
      "Epoch 31/200\n",
      "learning rate:  0.000199411763\n",
      "101/101 [==============================] - 40s 366ms/step - loss: 0.2131 - f1_score: 0.8727 - val_loss: 1.0079 - val_f1_score: 0.7340\n",
      "Epoch 32/200\n",
      "learning rate:  0.000198823516\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.1968 - f1_score: 0.9004 - val_loss: 1.0144 - val_f1_score: 0.7744\n",
      "Epoch 33/200\n",
      "learning rate:  0.000198235284\n",
      "101/101 [==============================] - 39s 361ms/step - loss: 0.1924 - f1_score: 0.9040 - val_loss: 1.1734 - val_f1_score: 0.6814\n",
      "Epoch 34/200\n",
      "learning rate:  0.000197647052\n",
      "101/101 [==============================] - 40s 363ms/step - loss: 0.1366 - f1_score: 0.9071 - val_loss: 1.0274 - val_f1_score: 0.7535\n",
      "Epoch 35/200\n",
      "learning rate:  0.000197058805\n",
      "101/101 [==============================] - 39s 364ms/step - loss: 0.0884 - f1_score: 0.9326 - val_loss: 1.0564 - val_f1_score: 0.7624\n",
      "Epoch 36/200\n",
      "learning rate:  0.000196470588\n",
      "101/101 [==============================] - 38s 359ms/step - loss: 0.1902 - f1_score: 0.8771 - val_loss: 1.1725 - val_f1_score: 0.7378\n",
      "Epoch 37/200\n",
      "learning rate:  0.000195882341\n",
      "101/101 [==============================] - 39s 365ms/step - loss: 0.2337 - f1_score: 0.8516 - val_loss: 1.1696 - val_f1_score: 0.7330\n",
      "Epoch 38/200\n",
      "learning rate:  0.000195294124\n",
      "101/101 [==============================] - 40s 375ms/step - loss: 0.2606 - f1_score: 0.8486 - val_loss: 1.1053 - val_f1_score: 0.6642\n",
      "Epoch 39/200\n",
      "learning rate:  0.000194705877\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.0661 - f1_score: 0.9265 - val_loss: 1.2667 - val_f1_score: 0.7421\n",
      "Epoch 40/200\n",
      "learning rate:  0.000194117645\n",
      "101/101 [==============================] - 38s 364ms/step - loss: 0.2522 - f1_score: 0.8831 - val_loss: 1.0493 - val_f1_score: 0.7287\n",
      "Epoch 41/200\n",
      "learning rate:  0.000193529413\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.1421 - f1_score: 0.9148 - val_loss: 0.9599 - val_f1_score: 0.7243\n",
      "Epoch 42/200\n",
      "learning rate:  0.000192941166\n",
      "101/101 [==============================] - 39s 361ms/step - loss: 0.2064 - f1_score: 0.8917 - val_loss: 1.0632 - val_f1_score: 0.7568\n",
      "Epoch 43/200\n",
      "learning rate:  0.000192352934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 39s 364ms/step - loss: 0.0840 - f1_score: 0.9313 - val_loss: 1.0275 - val_f1_score: 0.7580\n",
      "Epoch 44/200\n",
      "learning rate:  0.000191764702\n",
      "101/101 [==============================] - 39s 364ms/step - loss: 0.0513 - f1_score: 0.9521 - val_loss: 1.0205 - val_f1_score: 0.7543\n",
      "Epoch 45/200\n",
      "learning rate:  0.000191176456\n",
      "101/101 [==============================] - 40s 363ms/step - loss: 0.0632 - f1_score: 0.9611 - val_loss: 0.9355 - val_f1_score: 0.7672\n",
      "Epoch 46/200\n",
      "learning rate:  0.000190588224\n",
      "101/101 [==============================] - 40s 363ms/step - loss: 0.0395 - f1_score: 0.9746 - val_loss: 0.8553 - val_f1_score: 0.7695\n",
      "Epoch 47/200\n",
      "learning rate:  0.000189999992\n",
      "101/101 [==============================] - 39s 362ms/step - loss: 0.0226 - f1_score: 0.9819 - val_loss: 0.9221 - val_f1_score: 0.7564\n",
      "Epoch 48/200\n",
      "learning rate:  0.000189411759\n",
      "101/101 [==============================] - 40s 364ms/step - loss: 0.0215 - f1_score: 0.9775 - val_loss: 0.8391 - val_f1_score: 0.7886\n",
      "Epoch 49/200\n",
      "learning rate:  0.000188823527\n",
      "101/101 [==============================] - 39s 361ms/step - loss: 0.0180 - f1_score: 0.9808 - val_loss: 0.9043 - val_f1_score: 0.8032\n",
      "Epoch 50/200\n",
      "learning rate:  0.000188235281\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.3276 - f1_score: 0.8427 - val_loss: 1.5581 - val_f1_score: 0.6481\n",
      "Epoch 51/200\n",
      "learning rate:  0.000187647049\n",
      "101/101 [==============================] - 40s 361ms/step - loss: 0.3339 - f1_score: 0.8256 - val_loss: 1.3285 - val_f1_score: 0.6645\n",
      "Epoch 52/200\n",
      "learning rate:  0.000187058817\n",
      "101/101 [==============================] - 40s 376ms/step - loss: 0.1467 - f1_score: 0.8987 - val_loss: 1.2154 - val_f1_score: 0.7030\n",
      "Epoch 53/200\n",
      "learning rate:  0.000186470585\n",
      "101/101 [==============================] - 39s 364ms/step - loss: 0.1668 - f1_score: 0.8848 - val_loss: 1.8600 - val_f1_score: 0.7097\n",
      "Epoch 54/200\n",
      "learning rate:  0.000185882353\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 0.1291 - f1_score: 0.9186 - val_loss: 1.2358 - val_f1_score: 0.7314\n",
      "Epoch 55/200\n",
      "learning rate:  0.000185294106\n",
      "101/101 [==============================] - 40s 362ms/step - loss: 0.2494 - f1_score: 0.8636 - val_loss: 0.9277 - val_f1_score: 0.7323\n",
      "Epoch 56/200\n",
      "learning rate:  0.000184705888\n",
      "101/101 [==============================] - 40s 361ms/step - loss: 0.0824 - f1_score: 0.9405 - val_loss: 0.7145 - val_f1_score: 0.7855\n",
      "Epoch 57/200\n",
      "learning rate:  0.000184117642\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.0943 - f1_score: 0.9545 - val_loss: 0.7010 - val_f1_score: 0.7947\n",
      "Epoch 58/200\n",
      "learning rate:  0.000183529395\n",
      "101/101 [==============================] - 39s 360ms/step - loss: 0.0246 - f1_score: 0.9735 - val_loss: 0.8504 - val_f1_score: 0.7949\n",
      "Epoch 59/200\n",
      "learning rate:  0.000182941178\n",
      "101/101 [==============================] - 38s 361ms/step - loss: 0.0188 - f1_score: 0.9875 - val_loss: 0.8104 - val_f1_score: 0.7763\n",
      "Epoch 60/200\n",
      "learning rate:  0.000182352931\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.0797 - f1_score: 0.9586 - val_loss: 0.9507 - val_f1_score: 0.7732\n",
      "Epoch 61/200\n",
      "learning rate:  0.000181764684\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 0.0505 - f1_score: 0.9640 - val_loss: 1.0778 - val_f1_score: 0.7491\n",
      "Epoch 62/200\n",
      "learning rate:  0.000181176467\n",
      "101/101 [==============================] - 38s 360ms/step - loss: 0.0374 - f1_score: 0.9645 - val_loss: 0.8162 - val_f1_score: 0.7973\n",
      "Epoch 63/200\n",
      "learning rate:  0.00018058822\n",
      "101/101 [==============================] - 38s 360ms/step - loss: 0.0115 - f1_score: 0.9851 - val_loss: 0.8467 - val_f1_score: 0.8009\n",
      "Epoch 64/200\n",
      "learning rate:  0.00018\n",
      "101/101 [==============================] - 38s 360ms/step - loss: 0.0065 - f1_score: 0.9827 - val_loss: 0.8730 - val_f1_score: 0.7984\n",
      "Epoch 65/200\n",
      "learning rate:  0.000179411756\n",
      "101/101 [==============================] - 40s 377ms/step - loss: 0.0055 - f1_score: 0.9922 - val_loss: 0.8582 - val_f1_score: 0.7822\n",
      "Epoch 66/200\n",
      "learning rate:  0.000178823524\n",
      "101/101 [==============================] - 40s 366ms/step - loss: 0.0297 - f1_score: 0.9730 - val_loss: 0.9985 - val_f1_score: 0.7369\n",
      "Epoch 67/200\n",
      "learning rate:  0.000178235292\n",
      "101/101 [==============================] - 40s 362ms/step - loss: 0.3055 - f1_score: 0.9100 - val_loss: 1.2005 - val_f1_score: 0.6424\n",
      "Epoch 68/200\n",
      "learning rate:  0.000177647045\n",
      "101/101 [==============================] - 39s 367ms/step - loss: 0.3046 - f1_score: 0.8584 - val_loss: 1.1259 - val_f1_score: 0.7522\n",
      "Epoch 69/200\n",
      "learning rate:  0.000177058828\n",
      "101/101 [==============================] - 39s 363ms/step - loss: 0.2461 - f1_score: 0.8692 - val_loss: 0.9408 - val_f1_score: 0.7247\n",
      "Epoch 70/200\n",
      "learning rate:  0.000176470581\n",
      "101/101 [==============================] - 39s 365ms/step - loss: 0.0888 - f1_score: 0.9394 - val_loss: 0.9497 - val_f1_score: 0.7543\n",
      "Epoch 71/200\n",
      "learning rate:  0.000175882335\n",
      "101/101 [==============================] - 38s 360ms/step - loss: 0.0586 - f1_score: 0.9625 - val_loss: 0.8733 - val_f1_score: 0.7649\n",
      "Epoch 72/200\n",
      "learning rate:  0.000175294117\n",
      "101/101 [==============================] - 40s 364ms/step - loss: 0.0705 - f1_score: 0.9528 - val_loss: 0.8627 - val_f1_score: 0.7935\n",
      "Epoch 73/200\n",
      "learning rate:  0.00017470587\n",
      "101/101 [==============================] - 38s 360ms/step - loss: 0.0190 - f1_score: 0.9787 - val_loss: 0.9104 - val_f1_score: 0.8003\n",
      "Epoch 74/200\n",
      "learning rate:  0.000174117653\n",
      "101/101 [==============================] - 40s 360ms/step - loss: 0.0127 - f1_score: 0.9838 - val_loss: 1.0089 - val_f1_score: 0.7919\n",
      "Epoch 75/200\n",
      "learning rate:  0.000173529406\n",
      "101/101 [==============================] - 39s 359ms/step - loss: 0.0241 - f1_score: 0.9759 - val_loss: 0.9482 - val_f1_score: 0.8022\n",
      "Epoch 76/200\n",
      "learning rate:  0.00017294116\n",
      "101/101 [==============================] - 39s 365ms/step - loss: 0.0193 - f1_score: 0.9837 - val_loss: 1.0470 - val_f1_score: 0.7911\n",
      "Epoch 77/200\n",
      "learning rate:  0.000172352942\n",
      "101/101 [==============================] - 39s 360ms/step - loss: 0.0675 - f1_score: 0.9726 - val_loss: 1.0045 - val_f1_score: 0.7576\n",
      "Epoch 78/200\n",
      "learning rate:  0.000171764696\n",
      "101/101 [==============================] - 38s 359ms/step - loss: 0.3667 - f1_score: 0.8684 - val_loss: 0.9922 - val_f1_score: 0.7013\n",
      "Epoch 79/200\n",
      "learning rate:  0.000171176463\n",
      "101/101 [==============================] - 38s 361ms/step - loss: 0.2436 - f1_score: 0.8656 - val_loss: 0.8691 - val_f1_score: 0.7882\n",
      "Epoch 80/200\n",
      "learning rate:  0.000170588231\n",
      "101/101 [==============================] - 39s 360ms/step - loss: 0.1538 - f1_score: 0.8995 - val_loss: 0.8499 - val_f1_score: 0.7690\n",
      "Epoch 81/200\n",
      "learning rate:  0.000169999985\n",
      "101/101 [==============================] - 40s 378ms/step - loss: 0.0973 - f1_score: 0.9533 - val_loss: 0.8370 - val_f1_score: 0.8119\n",
      "Epoch 82/200\n",
      "learning rate:  0.000169411753\n",
      "101/101 [==============================] - 39s 363ms/step - loss: 0.0441 - f1_score: 0.9635 - val_loss: 0.7438 - val_f1_score: 0.8291\n",
      "Epoch 83/200\n",
      "learning rate:  0.000168823521\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.0147 - f1_score: 0.9834 - val_loss: 0.7409 - val_f1_score: 0.8176\n",
      "Epoch 84/200\n",
      "learning rate:  0.000168235289\n",
      "101/101 [==============================] - 39s 365ms/step - loss: 0.0040 - f1_score: 0.9901 - val_loss: 0.8163 - val_f1_score: 0.8436\n",
      "Epoch 85/200\n",
      "learning rate:  0.000167647057\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 0.0015 - f1_score: 1.0000 - val_loss: 0.8478 - val_f1_score: 0.8454\n",
      "Epoch 86/200\n",
      "learning rate:  0.00016705881\n",
      "101/101 [==============================] - 38s 364ms/step - loss: 0.0042 - f1_score: 0.9908 - val_loss: 0.9253 - val_f1_score: 0.8160\n",
      "Epoch 87/200\n",
      "learning rate:  0.000166470592\n",
      "101/101 [==============================] - 40s 363ms/step - loss: 0.0060 - f1_score: 0.9920 - val_loss: 0.8407 - val_f1_score: 0.7988\n",
      "Epoch 88/200\n",
      "learning rate:  0.000165882346\n",
      "101/101 [==============================] - 38s 364ms/step - loss: 0.0108 - f1_score: 0.9882 - val_loss: 0.8781 - val_f1_score: 0.8270\n",
      "Epoch 89/200\n",
      "learning rate:  0.000165294099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 39s 372ms/step - loss: 0.0014 - f1_score: 1.0000 - val_loss: 0.8003 - val_f1_score: 0.8376\n",
      "Epoch 90/200\n",
      "learning rate:  0.000164705882\n",
      "101/101 [==============================] - 40s 362ms/step - loss: 0.0117 - f1_score: 0.9911 - val_loss: 0.8628 - val_f1_score: 0.8130\n",
      "Epoch 91/200\n",
      "learning rate:  0.000164117635\n",
      "101/101 [==============================] - 40s 375ms/step - loss: 0.0045 - f1_score: 0.9892 - val_loss: 0.9166 - val_f1_score: 0.8345\n",
      "Epoch 92/200\n",
      "learning rate:  0.000163529403\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 0.0275 - f1_score: 0.9832 - val_loss: 0.9996 - val_f1_score: 0.7827\n",
      "Epoch 93/200\n",
      "learning rate:  0.000162941171\n",
      "101/101 [==============================] - 38s 360ms/step - loss: 0.0979 - f1_score: 0.9537 - val_loss: 0.9701 - val_f1_score: 0.7818\n",
      "Epoch 94/200\n",
      "learning rate:  0.000162352939\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 0.0525 - f1_score: 0.9545 - val_loss: 1.4280 - val_f1_score: 0.7299\n",
      "Epoch 95/200\n",
      "learning rate:  0.000161764707\n",
      "101/101 [==============================] - 41s 371ms/step - loss: 0.2270 - f1_score: 0.8713 - val_loss: 1.1866 - val_f1_score: 0.7471\n",
      "Epoch 96/200\n",
      "learning rate:  0.00016117646\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 0.2514 - f1_score: 0.8437 - val_loss: 0.8238 - val_f1_score: 0.7588\n",
      "Epoch 97/200\n",
      "learning rate:  0.000160588228\n",
      "101/101 [==============================] - 38s 360ms/step - loss: 0.1165 - f1_score: 0.9129 - val_loss: 0.8158 - val_f1_score: 0.7765\n",
      "Epoch 98/200\n",
      "learning rate:  0.00016\n",
      "101/101 [==============================] - 38s 360ms/step - loss: 0.0212 - f1_score: 0.9794 - val_loss: 0.8994 - val_f1_score: 0.7909\n",
      "Epoch 99/200\n",
      "learning rate:  0.000159411764\n",
      "101/101 [==============================] - 39s 364ms/step - loss: 0.0264 - f1_score: 0.9732 - val_loss: 0.8371 - val_f1_score: 0.8421\n",
      "Epoch 100/200\n",
      "learning rate:  0.000158823517\n",
      "101/101 [==============================] - 39s 359ms/step - loss: 0.0075 - f1_score: 0.9936 - val_loss: 0.6965 - val_f1_score: 0.8489\n",
      "Epoch 101/200\n",
      "learning rate:  0.000158235285\n",
      "101/101 [==============================] - 38s 368ms/step - loss: 0.0089 - f1_score: 0.9846 - val_loss: 0.8617 - val_f1_score: 0.8266\n",
      "Epoch 102/200\n",
      "learning rate:  0.000157647053\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.0057 - f1_score: 0.9904 - val_loss: 0.8930 - val_f1_score: 0.8307\n",
      "Epoch 103/200\n",
      "learning rate:  0.000157058821\n",
      "101/101 [==============================] - 39s 367ms/step - loss: 0.0319 - f1_score: 0.9714 - val_loss: 0.9474 - val_f1_score: 0.8162\n",
      "Epoch 104/200\n",
      "learning rate:  0.000156470574\n",
      "101/101 [==============================] - 39s 365ms/step - loss: 0.0210 - f1_score: 0.9811 - val_loss: 0.8418 - val_f1_score: 0.8190\n",
      "Epoch 105/200\n",
      "learning rate:  0.000155882342\n",
      "101/101 [==============================] - 39s 367ms/step - loss: 0.0068 - f1_score: 0.9899 - val_loss: 0.9198 - val_f1_score: 0.8351\n",
      "Epoch 106/200\n",
      "learning rate:  0.00015529411\n",
      "101/101 [==============================] - 39s 372ms/step - loss: 0.0081 - f1_score: 0.9884 - val_loss: 0.9365 - val_f1_score: 0.8349\n",
      "Epoch 107/200\n",
      "learning rate:  0.000154705878\n",
      "101/101 [==============================] - 41s 378ms/step - loss: 0.0022 - f1_score: 0.9934 - val_loss: 0.8039 - val_f1_score: 0.8472\n",
      "Epoch 108/200\n",
      "learning rate:  0.000154117646\n",
      "101/101 [==============================] - 39s 361ms/step - loss: 0.0022 - f1_score: 0.9936 - val_loss: 0.8842 - val_f1_score: 0.8439\n",
      "Epoch 109/200\n",
      "learning rate:  0.0001535294\n",
      "101/101 [==============================] - 39s 364ms/step - loss: 0.0040 - f1_score: 0.9905 - val_loss: 0.9258 - val_f1_score: 0.8572\n",
      "Epoch 110/200\n",
      "learning rate:  0.000152941182\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 6.6906e-04 - f1_score: 0.9992 - val_loss: 0.9009 - val_f1_score: 0.8611\n",
      "Epoch 111/200\n",
      "learning rate:  0.000152352935\n",
      "101/101 [==============================] - 39s 366ms/step - loss: 5.7987e-04 - f1_score: 1.0000 - val_loss: 0.8606 - val_f1_score: 0.8672\n",
      "Epoch 112/200\n",
      "learning rate:  0.000151764689\n",
      "101/101 [==============================] - 39s 361ms/step - loss: 7.4759e-04 - f1_score: 0.9979 - val_loss: 1.0130 - val_f1_score: 0.8443\n",
      "Epoch 113/200\n",
      "learning rate:  0.000151176457\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 2.6216e-04 - f1_score: 1.0000 - val_loss: 1.0044 - val_f1_score: 0.8488\n",
      "Epoch 114/200\n",
      "learning rate:  0.000150588239\n",
      "101/101 [==============================] - 39s 362ms/step - loss: 5.9427e-04 - f1_score: 0.9994 - val_loss: 1.0824 - val_f1_score: 0.8488\n",
      "Epoch 115/200\n",
      "learning rate:  0.000149999993\n",
      "101/101 [==============================] - 38s 364ms/step - loss: 0.0011 - f1_score: 0.9976 - val_loss: 0.9913 - val_f1_score: 0.8508\n",
      "Epoch 116/200\n",
      "learning rate:  0.000149411761\n",
      "101/101 [==============================] - 39s 369ms/step - loss: 1.5268e-04 - f1_score: 1.0000 - val_loss: 1.0088 - val_f1_score: 0.8525\n",
      "Epoch 117/200\n",
      "learning rate:  0.000148823514\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 4.8361e-04 - f1_score: 1.0000 - val_loss: 0.9850 - val_f1_score: 0.8596\n",
      "Epoch 118/200\n",
      "learning rate:  0.000148235296\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 6.3432e-04 - f1_score: 0.9992 - val_loss: 1.0666 - val_f1_score: 0.8437\n",
      "Epoch 119/200\n",
      "learning rate:  0.00014764705\n",
      "101/101 [==============================] - 38s 361ms/step - loss: 0.0107 - f1_score: 0.9984 - val_loss: 1.2352 - val_f1_score: 0.8129\n",
      "Epoch 120/200\n",
      "learning rate:  0.000147058818\n",
      "101/101 [==============================] - 38s 359ms/step - loss: 0.2737 - f1_score: 0.8870 - val_loss: 1.7005 - val_f1_score: 0.6153\n",
      "Epoch 121/200\n",
      "learning rate:  0.000146470586\n",
      "101/101 [==============================] - 40s 362ms/step - loss: 0.5078 - f1_score: 0.7982 - val_loss: 0.9073 - val_f1_score: 0.7366\n",
      "Epoch 122/200\n",
      "learning rate:  0.000145882339\n",
      "101/101 [==============================] - 38s 361ms/step - loss: 0.1199 - f1_score: 0.9050 - val_loss: 0.7871 - val_f1_score: 0.7819\n",
      "Epoch 123/200\n",
      "learning rate:  0.000145294107\n",
      "101/101 [==============================] - 39s 365ms/step - loss: 0.0412 - f1_score: 0.9616 - val_loss: 0.7723 - val_f1_score: 0.7821\n",
      "Epoch 124/200\n",
      "learning rate:  0.000144705875\n",
      "101/101 [==============================] - 40s 364ms/step - loss: 0.0229 - f1_score: 0.9779 - val_loss: 0.8186 - val_f1_score: 0.8212\n",
      "Epoch 125/200\n",
      "learning rate:  0.000144117643\n",
      "101/101 [==============================] - 39s 361ms/step - loss: 0.0053 - f1_score: 0.9936 - val_loss: 0.7669 - val_f1_score: 0.8286\n",
      "Epoch 126/200\n",
      "learning rate:  0.000143529411\n",
      "101/101 [==============================] - 38s 361ms/step - loss: 0.0027 - f1_score: 0.9939 - val_loss: 0.7517 - val_f1_score: 0.8422\n",
      "Epoch 127/200\n",
      "learning rate:  0.000142941164\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.0020 - f1_score: 0.9979 - val_loss: 0.8269 - val_f1_score: 0.8440\n",
      "Epoch 128/200\n",
      "learning rate:  0.000142352932\n",
      "101/101 [==============================] - 39s 364ms/step - loss: 0.0165 - f1_score: 0.9756 - val_loss: 0.7437 - val_f1_score: 0.8334\n",
      "Epoch 129/200\n",
      "learning rate:  0.0001417647\n",
      "101/101 [==============================] - 39s 361ms/step - loss: 0.0209 - f1_score: 0.9729 - val_loss: 0.9188 - val_f1_score: 0.8155\n",
      "Epoch 130/200\n",
      "learning rate:  0.000141176453\n",
      "101/101 [==============================] - 40s 363ms/step - loss: 0.3602 - f1_score: 0.9526 - val_loss: 0.9566 - val_f1_score: 0.7686\n",
      "Epoch 131/200\n",
      "learning rate:  0.000140588236\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.1261 - f1_score: 0.9338 - val_loss: 0.7057 - val_f1_score: 0.8374\n",
      "Epoch 132/200\n",
      "learning rate:  0.000139999989\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 0.0474 - f1_score: 0.9492 - val_loss: 0.7749 - val_f1_score: 0.8156\n",
      "Epoch 133/200\n",
      "learning rate:  0.000139411757\n",
      "101/101 [==============================] - 38s 361ms/step - loss: 0.0097 - f1_score: 0.9871 - val_loss: 0.8733 - val_f1_score: 0.7974\n",
      "Epoch 134/200\n",
      "learning rate:  0.000138823525\n",
      "101/101 [==============================] - 38s 362ms/step - loss: 0.0153 - f1_score: 0.9923 - val_loss: 0.7714 - val_f1_score: 0.8286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200\n",
      "learning rate:  0.000138235293\n",
      "101/101 [==============================] - 38s 360ms/step - loss: 0.0318 - f1_score: 0.9781 - val_loss: 0.7973 - val_f1_score: 0.8078\n",
      "Epoch 136/200\n",
      "learning rate:  0.000137647061\n",
      "101/101 [==============================] - 40s 366ms/step - loss: 0.0129 - f1_score: 0.9848 - val_loss: 0.8051 - val_f1_score: 0.8168\n",
      "Epoch 137/200\n",
      "learning rate:  0.000137058814\n",
      "101/101 [==============================] - 39s 363ms/step - loss: 0.0126 - f1_score: 0.9860 - val_loss: 0.7639 - val_f1_score: 0.8304\n",
      "Epoch 138/200\n",
      "learning rate:  0.000136470582\n",
      "101/101 [==============================] - 39s 362ms/step - loss: 0.0134 - f1_score: 0.9911 - val_loss: 0.8884 - val_f1_score: 0.7938\n",
      "Epoch 139/200\n",
      "learning rate:  0.00013588235\n",
      "101/101 [==============================] - 38s 363ms/step - loss: 0.0446 - f1_score: 0.9712 - val_loss: 0.9143 - val_f1_score: 0.8076\n",
      "Epoch 140/200\n",
      "learning rate:  0.000135294104\n",
      "101/101 [==============================] - 39s 366ms/step - loss: 0.0279 - f1_score: 0.9761 - val_loss: 0.8080 - val_f1_score: 0.8146\n",
      "Epoch 141/200\n",
      "learning rate:  0.000134705871\n",
      "101/101 [==============================] - 39s 363ms/step - loss: 0.0024 - f1_score: 0.9964 - val_loss: 0.8258 - val_f1_score: 0.8413\n",
      "Epoch 142/200\n",
      "learning rate:  0.000134117639\n",
      "101/101 [==============================] - 39s 361ms/step - loss: 0.0018 - f1_score: 0.9984 - val_loss: 0.7946 - val_f1_score: 0.8420\n",
      "Epoch 143/200\n",
      "learning rate:  0.000133529407\n",
      "101/101 [==============================] - 39s 364ms/step - loss: 7.0360e-04 - f1_score: 0.9994 - val_loss: 0.8554 - val_f1_score: 0.8405\n",
      "Epoch 144/200\n",
      "learning rate:  0.000132941175\n",
      "101/101 [==============================] - 38s 360ms/step - loss: 0.0021 - f1_score: 0.9982 - val_loss: 0.9739 - val_f1_score: 0.8302\n",
      "Epoch 145/200\n",
      "learning rate:  0.000132352943\n",
      "101/101 [==============================] - 39s 371ms/step - loss: 7.7911e-04 - f1_score: 0.9981 - val_loss: 0.9523 - val_f1_score: 0.8296\n",
      "Epoch 146/200\n",
      "learning rate:  0.000131764697\n",
      "101/101 [==============================] - 39s 365ms/step - loss: 0.0011 - f1_score: 0.9975 - val_loss: 0.9485 - val_f1_score: 0.8222\n",
      "Epoch 147/200\n",
      "learning rate:  0.000131176464\n",
      "101/101 [==============================] - 40s 364ms/step - loss: 0.0017 - f1_score: 0.9972 - val_loss: 0.8263 - val_f1_score: 0.8416\n",
      "Epoch 148/200\n",
      "learning rate:  0.000130588232\n",
      "101/101 [==============================] - 39s 369ms/step - loss: 7.0752e-04 - f1_score: 0.9982 - val_loss: 0.9012 - val_f1_score: 0.8198\n",
      "Epoch 149/200\n",
      "learning rate:  0.00013\n",
      "101/101 [==============================] - 40s 375ms/step - loss: 0.0027 - f1_score: 0.9950 - val_loss: 0.9228 - val_f1_score: 0.8349\n",
      "Epoch 150/200\n",
      "learning rate:  0.000129411754\n",
      "101/101 [==============================] - 39s 365ms/step - loss: 3.7110e-04 - f1_score: 0.9984 - val_loss: 0.9512 - val_f1_score: 0.8294\n",
      "Epoch 00150: early stopping\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    base_model.trainable = True\n",
    "    model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=[F1Score(num_classes=n_classes, average='macro')])\n",
    "epochs = 200\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=get_callbacks(patience=50, plot_path=join(PATH.result, 'proposed3', 'fix_pretrained_model_nadam_lr_scheduler'), init_lr=2e-4, epochs=epochs, warmup_epoch=30, min_lr=1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ec114",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c990309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  label\n",
       "index                  \n",
       "0       tile-glue_strip\n",
       "1             grid-good\n",
       "2       transistor-good\n",
       "3      tile-gray_stroke\n",
       "4             tile-good\n",
       "...                 ...\n",
       "2149   tile-gray_stroke\n",
       "2150         screw-good\n",
       "2151          grid-good\n",
       "2152         cable-good\n",
       "2153        zipper-good\n",
       "\n",
       "[2154 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file_path = join(PATH.output, 'proposed3_fine_tuning_nadam_lr_scheduler.csv')\n",
    "\n",
    "pred_test = model.predict(test_ds)\n",
    "submission = pd.read_csv(join(PATH.input, 'sample_submission.csv'), index_col=0)\n",
    "submission['label'] = y_enc.inverse_transform(pred_test)\n",
    "submission.to_csv(submission_file_path)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3912a8",
   "metadata": {},
   "source": [
    "# 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4c06fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSubmitted': True, 'detail': 'Success'}\n"
     ]
    }
   ],
   "source": [
    "from dacon_submit_api.dacon_submit_api import post_submission_file\n",
    "\n",
    "result = post_submission_file(\n",
    "    submission_file_path,\n",
    "    '137ff236e305f302819b930b3b5b72e948603f23c5249a516c32b536d5187a03', \n",
    "    '235894', \n",
    "    '  ', \n",
    "    'proposed3_fine_tuning_nadam_lr_scheduler'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e507c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
